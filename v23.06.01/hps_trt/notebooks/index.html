<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HPS Plugin for TensorRT Notebooks &mdash; Merlin HugeCTR  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/HugeCTR/main/hps_trt/notebooks/index.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="HPS TensorRT Plugin Demo for TensorFlow Trained Model" href="demo_for_tf_trained_model.html" />
    <link rel="prev" title="Hierarchical Parameter Server Plugin for TensorRT" href="../../hierarchical_parameter_server/hps_trt_user_guide.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      After the HugeCTR <code>v23.08</code>, the offline inference  will be deprecated.
      Check out our HPS plugins for TensorRT and TensorFlow as alternatives.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">HUGECTR</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_user_guide.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_embedding_training_cache.html">Embedding Training Cache</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../hierarchical_parameter_server/index.html">Hierarchical Parameter Server</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../hierarchical_parameter_server/hps_database_backend.html">HPS Database Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hierarchical_parameter_server/hps_tf_user_guide.html">HPS Plugin for TensorFlow</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../hierarchical_parameter_server/hps_trt_user_guide.html">HPS Plugin for TensorRT</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Notebooks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="demo_for_tf_trained_model.html">HPS TensorRT Plugin Demo for TensorFlow Trained Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="demo_for_pytorch_trained_model.html">HPS TensorRT Plugin Demo for PyTorch Trained Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="demo_for_hugectr_trained_model.html">HPS TensorRT Plugin Demo for HugeCTR Trained Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../hierarchical_parameter_server/hps_trt_api/index.html">API Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../hierarchical_parameter_server/hps_dlrm_benchmark.html">Benchmark HPS-integrated DLRM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse_operation_kit.html">Sparse Operation Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/multi-modal-data/index.html">Multi-modal Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../hierarchical_parameter_server/index.html">Hierarchical Parameter Server</a></li>
          <li class="breadcrumb-item"><a href="../../hierarchical_parameter_server/hps_trt_user_guide.html">Hierarchical Parameter Server Plugin for TensorRT</a></li>
      <li class="breadcrumb-item active">HPS Plugin for TensorRT Notebooks</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="hps-plugin-for-tensorrt-notebooks">
<h1>HPS Plugin for TensorRT Notebooks<a class="headerlink" href="#hps-plugin-for-tensorrt-notebooks" title="Permalink to this heading"></a></h1>
<p>This directory contains a set of Jupyter notebooks that demonstrate how to use the HPS plugin for TensorRT.</p>
<section id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this heading"></a></h2>
<p>The simplest way to run a one of our notebooks is with a Docker container.
A container provides a self-contained, isolated, and reproducible environment for repetitive experiments.
Docker images are available from the NVIDIA GPU Cloud (NGC).
If you prefer to build the HugeCTR Docker image on your own, refer to <a class="reference external" href="https://nvidia-merlin.github.io/HugeCTR/master/hugectr_contributor_guide.html#set-up-the-development-environment-with-merlin-containers">Set Up the Development Environment With Merlin Containers</a>.</p>
<section id="pull-the-container-from-ngc">
<h3>Pull the Container from NGC<a class="headerlink" href="#pull-the-container-from-ngc" title="Permalink to this heading"></a></h3>
<p>Pull a container based on the modeling framework and notebook that you want to run.</p>
<p>To run the <a class="reference internal" href="demo_for_tf_trained_model.html"><span class="std std-doc">demo_for_tf_trained_model.ipynb</span></a> notebook, pull the Merlin TensorFlow container:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-tensorflow:23.02
</pre></div>
</div>
<p>To run the <a class="reference internal" href="demo_for_pytorch_trained_model.html"><span class="std std-doc">demo_for_pytorch_trained_model.ipynb</span></a> notebook, pull the Merlin PyTorch container:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-pytorch:23.02
</pre></div>
</div>
<p>To run the <a class="reference internal" href="demo_for_hugectr_trained_model.html"><span class="std std-doc">demo_for_hugectr_trained_model.ipynb</span></a> notebook, pull the Merlin HugeCTR container:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-hugectr:23.02
</pre></div>
</div>
<p>The HPS TensorRT plugin is installed in all the containers.</p>
</section>
<section id="clone-the-hugectr-repository">
<h3>Clone the HugeCTR Repository<a class="headerlink" href="#clone-the-hugectr-repository" title="Permalink to this heading"></a></h3>
<p>Use the following command to clone the HugeCTR repository:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/NVIDIA-Merlin/HugeCTR
</pre></div>
</div>
</section>
<section id="start-the-jupyter-notebook">
<h3>Start the Jupyter Notebook<a class="headerlink" href="#start-the-jupyter-notebook" title="Permalink to this heading"></a></h3>
<ol class="arabic">
<li><p>Launch the container in interactive mode (mount the HugeCTR root directory into the container for your convenience) by running the following command.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--runtime<span class="o">=</span>nvidia<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--cap-add<span class="w"> </span>SYS_NICE<span class="w"> </span>-u<span class="w"> </span><span class="k">$(</span>id<span class="w"> </span>-u<span class="k">)</span>:<span class="k">$(</span>id<span class="w"> </span>-g<span class="k">)</span><span class="w"> </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/hugectr<span class="w"> </span>-w<span class="w"> </span>/hugectr<span class="w"> </span>-p<span class="w"> </span><span class="m">8888</span>:8888<span class="w"> </span>nvcr.io/nvidia/merlin/&lt;container-name&gt;:23.02
</pre></div>
</div>
</li>
<li><p>Start Jupyter using these commands:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/hugectr/hps_trt/notebooks
jupyter-notebook<span class="w"> </span>--allow-root<span class="w"> </span>--ip<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8888</span><span class="w"> </span>--NotebookApp.token<span class="o">=</span><span class="s1">&#39;hugectr&#39;</span>
</pre></div>
</div>
</li>
<li><p>Connect to your host machine using the 8888 port by accessing its IP address or name from your web browser: <code class="docutils literal notranslate"><span class="pre">http://[host</span> <span class="pre">machine]:8888</span></code></p>
<p>Use the token available from the output by running the command above to log in. For example:</p>
<p><code class="docutils literal notranslate"><span class="pre">http://[host</span> <span class="pre">machine]:8888/?token=aae96ae9387cd28151868fee318c3b3581a2d794f3b25c6b</span></code></p>
</li>
</ol>
</section>
</section>
<section id="notebook-list">
<h2>Notebook List<a class="headerlink" href="#notebook-list" title="Permalink to this heading"></a></h2>
<p>Here’s a list of notebooks that you can run:</p>
<ul class="simple">
<li><p><a class="reference internal" href="demo_for_tf_trained_model.html"><span class="std std-doc">demo_for_tf_trained_model.ipynb</span></a>: Demonstrates how to train with TensorFlow and then build the HPS-integrated TensorRT engine for deployment.</p></li>
<li><p><a class="reference internal" href="demo_for_pytorch_trained_model.html"><span class="std std-doc">demo_for_pytorch_trained_model.ipynb</span></a>: Demonstrates how to train with PyTorch and then build the HPS-integrated TensorRT engine for deployment.</p></li>
<li><p><a class="reference internal" href="demo_for_hugectr_trained_model.html"><span class="std std-doc">demo_for_hugectr_trained_model.ipynb</span></a>: Demonstrates how to train with HugeCTR and then build the HPS-integrated TensorRT engine for deployment.</p></li>
</ul>
</section>
<section id="system-specifications">
<h2>System Specifications<a class="headerlink" href="#system-specifications" title="Permalink to this heading"></a></h2>
<p>The specifications of the system on which each notebook can run successfully are summarized in the table. The notebooks are verified on the system below but it does not mean the minimum requirements.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Notebook</p></th>
<th class="head"><p>CPU</p></th>
<th class="head"><p>GPU</p></th>
<th class="head"><p>#GPUs</p></th>
<th class="head"><p>Author</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="demo_for_tf_trained_model.html"><span class="std std-doc">demo_for_tf_trained_model.ipynb</span></a></p></td>
<td><p>Intel® Xeon® CPU E5-2698 v4 &#64; 2.20GHz<br />512 GB Memory</p></td>
<td><p>Tesla V100-SXM2-32GB<br />32 GB Memory</p></td>
<td><p>1</p></td>
<td><p>Kingsley Liu</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="demo_for_pytorch_trained_model.html"><span class="std std-doc">demo_for_pytorch_trained_model.ipynb</span></a></p></td>
<td><p>Intel® Xeon® CPU E5-2698 v4 &#64; 2.20GHz<br />512 GB Memory</p></td>
<td><p>Tesla V100-SXM2-32GB<br />32 GB Memory</p></td>
<td><p>1</p></td>
<td><p>Kingsley Liu</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="demo_for_hugectr_trained_model.html"><span class="std std-doc">demo_for_hugectr_trained_model.ipynb</span></a></p></td>
<td><p>Intel® Xeon® CPU E5-2698 v4 &#64; 2.20GHz<br />512 GB Memory</p></td>
<td><p>Tesla V100-SXM2-32GB<br />32 GB Memory</p></td>
<td><p>1</p></td>
<td><p>Kingsley Liu</p></td>
</tr>
</tbody>
</table>
</section>
<div class="toctree-wrapper compound">
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../hierarchical_parameter_server/hps_trt_user_guide.html" class="btn btn-neutral float-left" title="Hierarchical Parameter Server Plugin for TensorRT" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demo_for_tf_trained_model.html" class="btn btn-neutral float-right" title="HPS TensorRT Plugin Demo for TensorFlow Trained Model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v23.06.01
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../v23.05.00/index.html">v23.05.00</a></dd>
      <dd><a href="../../../v23.05.01/index.html">v23.05.01</a></dd>
      <dd><a href="../../../v23.06.00/index.html">v23.06.00</a></dd>
      <dd><a href="index.html">v23.06.01</a></dd>
      <dd><a href="../../../v23.08.00/index.html">v23.08.00</a></dd>
      <dd><a href="../../../v23.09.00/index.html">v23.09.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>