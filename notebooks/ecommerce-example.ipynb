{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Merlin ETL, training and inference demo on the e-Commerce behavior data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will be using the [eCommerce behavior data from multi category store](https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store) from [REES46 Marketing Platform](https://rees46.com/) as our dataset. This tutorial is built upon the NVIDIA RecSys 2020 [tutorial](https://recsys.acm.org/recsys20/tutorials/). \n",
    "\n",
    "This jupyter notebook provides the code to preprocess the dataset and generate the train, validation and test sets for the remainder of the tutorial. We define our own goal and filter the dataset accordingly.\n",
    "\n",
    "For our tutorial, we decided that our goal is to predict if a user purchased an item:\n",
    "\n",
    "-  Positive: User purchased an item\n",
    "-  Negative: User added an item to the cart, but did not purchase it (in the same session)    \n",
    "\n",
    "\n",
    "We split the dataset into train, validation and test set by the timestamp:\n",
    "- Training: October 2019 - February 2020\n",
    "- Validation: March 2020\n",
    "-  Test: April 2020\n",
    "\n",
    "We remove AddToCart Events from a session, if in the same session the same item was purchased.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data](#1)\n",
    "1. [ETL with NVTabular](#2)\n",
    "1. [Training with HugeCTR](#3)\n",
    "1. [HugeCTR inference](#4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Data\n",
    "First, we download and unzip the raw data.\n",
    "\n",
    "Note: the dataset is ~11GB and will take a while to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gdown in ./.local/lib/python3.8/site-packages (3.12.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/merlin/lib/python3.8/site-packages (from gdown) (4.60.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/merlin/lib/python3.8/site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.8/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/envs/merlin/lib/python3.8/site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/merlin/lib/python3.8/site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/merlin/lib/python3.8/site-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/merlin/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/merlin/lib/python3.8/site-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/envs/merlin/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
      "To: /hugectr/notebooks/2020-Feb.csv.gz\n",
      "2.35GB [00:23, 98.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
      "To: /hugectr/notebooks/2020-Feb.csv.gz\n",
      "2.35GB [00:24, 97.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zr_RXpGvOWN2PrWI6itWL8HnRsCpyqz8\n",
      "To: /hugectr/notebooks/2020-Mar.csv.gz\n",
      "2.42GB [00:40, 59.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1g5WoIgLe05UMdREbxAjh0bEFgVCjA1UL\n",
      "To: /hugectr/notebooks/2020-Apr.csv.gz\n",
      "2.93GB [00:33, 86.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qZIwMbMgMmgDC5EoMdJ8aI9lQPsWA3-P\n",
      "To: /hugectr/notebooks/2019-Dec.csv.gz\n",
      "2.95GB [01:04, 45.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1x5ohrrZNhWQN4Q-zww0RmXOwctKHH9PT\n",
      "To: /hugectr/notebooks/2020-Jan.csv.gz\n",
      "2.39GB [00:24, 99.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export HOME=$PWD\n",
    "pip install gdown --user\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1zr_RXpGvOWN2PrWI6itWL8HnRsCpyqz8\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1g5WoIgLe05UMdREbxAjh0bEFgVCjA1UL\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1qZIwMbMgMmgDC5EoMdJ8aI9lQPsWA3-P\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1x5ohrrZNhWQN4Q-zww0RmXOwctKHH9PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-Feb.csv.gz',\n",
       " '2020-Mar.csv.gz',\n",
       " '2020-Apr.csv.gz',\n",
       " '2019-Dec.csv.gz',\n",
       " '2020-Jan.csv.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob  \n",
    "\n",
    "list_files = glob.glob('*.csv.gz')\n",
    "list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction and initial preprocessing\n",
    "\n",
    "We extract a few relevant columns from the raw datasets and parse date columns into several atomic colunns (day, month...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./dataset’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Feb.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [03:24<13:36, 204.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Mar.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [06:54<10:24, 208.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Apr.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [11:01<07:31, 225.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-Dec.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [15:15<03:56, 236.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Jan.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [18:45<00:00, 225.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_files(file):\n",
    "    df_tmp = pd.read_csv(file, compression='gzip')\n",
    "    df_tmp['session_purchase'] =  df_tmp['user_session'] + '_' + df_tmp['product_id'].astype(str)\n",
    "    df_purchase = df_tmp[df_tmp['event_type']=='purchase']\n",
    "    df_cart = df_tmp[df_tmp['event_type']=='cart']\n",
    "    df_purchase = df_purchase[df_purchase['session_purchase'].isin(df_cart['session_purchase'])]\n",
    "    df_cart = df_cart[~(df_cart['session_purchase'].isin(df_purchase['session_purchase']))]\n",
    "    df_cart['target'] = 0\n",
    "    df_purchase['target'] = 1\n",
    "    df = pd.concat([df_cart, df_purchase])\n",
    "    df = df.drop('category_id', axis=1)\n",
    "    df = df.drop('session_purchase', axis=1)\n",
    "    df[['cat_0', 'cat_1', 'cat_2', 'cat_3']] = df['category_code'].str.split(\"\\.\", n = 3, expand = True).fillna('NA')\n",
    "    df['brand'] = df['brand'].fillna('NA')\n",
    "    df = df.drop('category_code', axis=1)\n",
    "    df['timestamp'] = pd.to_datetime(df['event_time'].str.replace(' UTC', ''))\n",
    "    df['ts_hour'] = df['timestamp'].dt.hour\n",
    "    df['ts_minute'] = df['timestamp'].dt.minute\n",
    "    df['ts_weekday'] = df['timestamp'].dt.weekday\n",
    "    df['ts_day'] = df['timestamp'].dt.day\n",
    "    df['ts_month'] = df['timestamp'].dt.month\n",
    "    df['ts_year'] = df['timestamp'].dt.year\n",
    "    df.to_csv('./dataset/' + file.replace('.gz', ''), index=False)\n",
    "    \n",
    "!mkdir ./dataset\n",
    "for file in tqdm(list_files):\n",
    "    print(file)\n",
    "    process_files(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/validation/test data\n",
    "\n",
    "Next, we split the data into train, validation and test sets. We will be using 3 months for training, 1 month for validation and 1 month for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = []\n",
    "list_files = glob.glob('./dataset/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 nobody nogroup 479323170 Apr 27 06:07 ./dataset/2019-Dec.csv\n",
      "-rw-r--r-- 1 nobody nogroup 455992639 Apr 27 06:03 ./dataset/2020-Apr.csv\n",
      "-rw-r--r-- 1 nobody nogroup 453967664 Apr 27 05:55 ./dataset/2020-Feb.csv\n",
      "-rw-r--r-- 1 nobody nogroup 375205173 Apr 27 06:11 ./dataset/2020-Jan.csv\n",
      "-rw-r--r-- 1 nobody nogroup 403896607 Apr 27 05:59 ./dataset/2020-Mar.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./dataset/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_files:\n",
    "    lp.append(pd.read_csv(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13184044, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(lp)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['ts_month']==4]\n",
    "df_valid = df[df['ts_month']==3]\n",
    "df_train = df[(df['ts_month']!=3)&(df['ts_month']!=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7949839, 19), (2461719, 19), (2772486, 19))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('./data/train.parquet', index=False)\n",
    "df_valid.to_parquet('./data/valid.parquet', index=False)\n",
    "df_test.to_parquet('./data/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>ts_minute</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>ts_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:18 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>100065078</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>568.61</td>\n",
       "      <td>526615078</td>\n",
       "      <td>5f0aab9f-f92e-4eff-b0d2-fcec5f553f01</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:18 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>5701246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.43</td>\n",
       "      <td>563902689</td>\n",
       "      <td>76cc9152-8a9f-43e9-b98a-ee484510f379</td>\n",
       "      <td>0</td>\n",
       "      <td>electronics</td>\n",
       "      <td>video</td>\n",
       "      <td>tv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:31 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>14701533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.42</td>\n",
       "      <td>520953435</td>\n",
       "      <td>5f1c7752-cf92-41fc-9a16-e8897a90eee8</td>\n",
       "      <td>0</td>\n",
       "      <td>electronics</td>\n",
       "      <td>video</td>\n",
       "      <td>projector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01 00:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:40 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1004855</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>123.30</td>\n",
       "      <td>519236281</td>\n",
       "      <td>e512f514-dc7f-4fc9-9042-e3955989d395</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:47 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1005100</td>\n",
       "      <td>samsung</td>\n",
       "      <td>140.28</td>\n",
       "      <td>550305600</td>\n",
       "      <td>bd7a37b6-420d-4575-8852-ac825aff39b5</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01 00:00:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id    brand   price    user_id  \\\n",
       "0  2020-02-01 00:00:18 UTC       cart   100065078   xiaomi  568.61  526615078   \n",
       "1  2020-02-01 00:00:18 UTC       cart     5701246      NaN   24.43  563902689   \n",
       "2  2020-02-01 00:00:31 UTC       cart    14701533      NaN  154.42  520953435   \n",
       "3  2020-02-01 00:00:40 UTC       cart     1004855   xiaomi  123.30  519236281   \n",
       "4  2020-02-01 00:00:47 UTC       cart     1005100  samsung  140.28  550305600   \n",
       "\n",
       "                           user_session  target         cat_0  cat_1  \\\n",
       "0  5f0aab9f-f92e-4eff-b0d2-fcec5f553f01       0  construction  tools   \n",
       "1  76cc9152-8a9f-43e9-b98a-ee484510f379       0   electronics  video   \n",
       "2  5f1c7752-cf92-41fc-9a16-e8897a90eee8       0   electronics  video   \n",
       "3  e512f514-dc7f-4fc9-9042-e3955989d395       0  construction  tools   \n",
       "4  bd7a37b6-420d-4575-8852-ac825aff39b5       0  construction  tools   \n",
       "\n",
       "       cat_2 cat_3            timestamp  ts_hour  ts_minute  ts_weekday  \\\n",
       "0      light   NaN  2020-02-01 00:00:18        0          0           5   \n",
       "1         tv   NaN  2020-02-01 00:00:18        0          0           5   \n",
       "2  projector   NaN  2020-02-01 00:00:31        0          0           5   \n",
       "3      light   NaN  2020-02-01 00:00:40        0          0           5   \n",
       "4      light   NaN  2020-02-01 00:00:47        0          0           5   \n",
       "\n",
       "   ts_day  ts_month  ts_year  \n",
       "0       1         2     2020  \n",
       "1       1         2     2020  \n",
       "2       1         2     2020  \n",
       "3       1         2     2020  \n",
       "4       1         2     2020  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Preprocessing with NVTabular\n",
    "\n",
    "Next, we will use NVTabular for preprocessing and engineering more features. \n",
    "\n",
    "But first, we need to import the necessary libraries and initialize a Dask GPU cluster for computation.\n",
    "\n",
    "### Initialize Dask GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# External Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import _pynvml_mem_size, device_mem_size\n",
    "\n",
    "print(nvt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './nvtabular_temp': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# define some information about where to get our data\n",
    "BASE_DIR = \"./nvtabular_temp\"\n",
    "!rm -r $BASE_DIR && mkdir $BASE_DIR\n",
    "input_path = './dataset'\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "output_path = os.path.join(BASE_DIR, \"output\")\n",
    "stats_path = os.path.join(BASE_DIR, \"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was tested on a DGX server with 8 GPUs. If you have less GPUs, modify the `NUM_GPUS` variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45727</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>270.02 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45727' processes=8 threads=8, memory=270.02 GB>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_GPUS = [0,1,2,3,4,5,6,7]\n",
    "#NUM_GPUS = [0]\n",
    "\n",
    "# Dask dashboard\n",
    "dashboard_port = \"8787\"\n",
    "\n",
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \",\".join([str(n) for n in NUM_GPUS])  # Delect devices to place workers\n",
    "device_limit_frac = 0.5      # Spill GPU-Worker memory to host at this limit.\n",
    "device_pool_frac = 0.6\n",
    "part_mem_frac = 0.05\n",
    "\n",
    "# Use total device size to calculate args.device_limit_frac\n",
    "device_size = device_mem_size(kind=\"total\")\n",
    "device_limit = int(device_limit_frac * device_size)\n",
    "device_pool_size = int(device_pool_frac * device_size)\n",
    "part_size = int(part_mem_frac * device_size)\n",
    "\n",
    "# Check if any device memory is already occupied\n",
    "\"\"\"\n",
    "for dev in visible_devices.split(\",\"):\n",
    "    fmem = _pynvml_mem_size(kind=\"free\", index=int(dev))\n",
    "    used = (device_size - fmem) / 1e9\n",
    "    if used > 1.0:\n",
    "        warnings.warn(f\"BEWARE - {used} GB is already occupied on device {int(dev)}!\")\n",
    "\"\"\"\n",
    "\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        n_workers=len(visible_devices.split(\",\")),\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        device_memory_limit = device_limit,\n",
    "        local_directory=dask_workdir,\n",
    "        dashboard_address=\":\" + dashboard_port,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 27 06:18:42 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.34       Driver Version: 455.34       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-PCIE-40GB      On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    31W / 250W |    828MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  A100-PCIE-40GB      On   | 00000000:24:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    32W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  A100-PCIE-40GB      On   | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  A100-PCIE-40GB      On   | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  A100-PCIE-40GB      On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  A100-PCIE-40GB      On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  A100-PCIE-40GB      On   | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  A100-PCIE-40GB      On   | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    34W / 250W |    415MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:40307': None,\n",
       " 'tcp://127.0.0.1:40585': None,\n",
       " 'tcp://127.0.0.1:41315': None,\n",
       " 'tcp://127.0.0.1:41327': None,\n",
       " 'tcp://127.0.0.1:43379': None,\n",
       " 'tcp://127.0.0.1:43641': None,\n",
       " 'tcp://127.0.0.1:44213': None,\n",
       " 'tcp://127.0.0.1:44837': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        # RMM may require the pool size to be a multiple of 256.\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=(device_pool_size // 256) * 256, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define NVTabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob.glob('./data/train.parquet')\n",
    "valid_paths = glob.glob('./data/valid.parquet')\n",
    "test_paths = glob.glob('./data/test.parquet')\n",
    "\n",
    "train_dataset = nvt.Dataset(train_paths, engine='parquet', part_mem_fraction=0.15)\n",
    "valid_dataset = nvt.Dataset(valid_paths, engine='parquet', part_mem_fraction=0.15)\n",
    "test_dataset = nvt.Dataset(test_paths, engine='parquet', part_mem_fraction=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>ts_minute</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>ts_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:18 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>100065078</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>568.61</td>\n",
       "      <td>526615078</td>\n",
       "      <td>5f0aab9f-f92e-4eff-b0d2-fcec5f553f01</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-02-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:18 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>5701246</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>24.43</td>\n",
       "      <td>563902689</td>\n",
       "      <td>76cc9152-8a9f-43e9-b98a-ee484510f379</td>\n",
       "      <td>0</td>\n",
       "      <td>electronics</td>\n",
       "      <td>video</td>\n",
       "      <td>tv</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-02-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:31 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>14701533</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>154.42</td>\n",
       "      <td>520953435</td>\n",
       "      <td>5f1c7752-cf92-41fc-9a16-e8897a90eee8</td>\n",
       "      <td>0</td>\n",
       "      <td>electronics</td>\n",
       "      <td>video</td>\n",
       "      <td>projector</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-02-01 00:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:40 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1004855</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>123.30</td>\n",
       "      <td>519236281</td>\n",
       "      <td>e512f514-dc7f-4fc9-9042-e3955989d395</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:47 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1005100</td>\n",
       "      <td>samsung</td>\n",
       "      <td>140.28</td>\n",
       "      <td>550305600</td>\n",
       "      <td>bd7a37b6-420d-4575-8852-ac825aff39b5</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-02-01 00:00:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id    brand   price    user_id  \\\n",
       "0  2020-02-01 00:00:18 UTC       cart   100065078   xiaomi  568.61  526615078   \n",
       "1  2020-02-01 00:00:18 UTC       cart     5701246     <NA>   24.43  563902689   \n",
       "2  2020-02-01 00:00:31 UTC       cart    14701533     <NA>  154.42  520953435   \n",
       "3  2020-02-01 00:00:40 UTC       cart     1004855   xiaomi  123.30  519236281   \n",
       "4  2020-02-01 00:00:47 UTC       cart     1005100  samsung  140.28  550305600   \n",
       "\n",
       "                           user_session  target         cat_0  cat_1  \\\n",
       "0  5f0aab9f-f92e-4eff-b0d2-fcec5f553f01       0  construction  tools   \n",
       "1  76cc9152-8a9f-43e9-b98a-ee484510f379       0   electronics  video   \n",
       "2  5f1c7752-cf92-41fc-9a16-e8897a90eee8       0   electronics  video   \n",
       "3  e512f514-dc7f-4fc9-9042-e3955989d395       0  construction  tools   \n",
       "4  bd7a37b6-420d-4575-8852-ac825aff39b5       0  construction  tools   \n",
       "\n",
       "       cat_2 cat_3            timestamp  ts_hour  ts_minute  ts_weekday  \\\n",
       "0      light  <NA>  2020-02-01 00:00:18        0          0           5   \n",
       "1         tv  <NA>  2020-02-01 00:00:18        0          0           5   \n",
       "2  projector  <NA>  2020-02-01 00:00:31        0          0           5   \n",
       "3      light  <NA>  2020-02-01 00:00:40        0          0           5   \n",
       "4      light  <NA>  2020-02-01 00:00:47        0          0           5   \n",
       "\n",
       "   ts_day  ts_month  ts_year  \n",
       "0       1         2     2020  \n",
       "1       1         2     2020  \n",
       "2       1         2     2020  \n",
       "3       1         2     2020  \n",
       "4       1         2     2020  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_ddf().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.to_ddf().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_time', 'event_type', 'product_id', 'brand', 'price', 'user_id',\n",
       "       'user_session', 'target', 'cat_0', 'cat_1', 'cat_2', 'cat_3',\n",
       "       'timestamp', 'ts_hour', 'ts_minute', 'ts_weekday', 'ts_day', 'ts_month',\n",
       "       'ts_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_ddf().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7949839"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.to_ddf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore a few feature engineering technique with NVTabular:\n",
    "\n",
    "- Creating cross features, e.g. `user_id` and `'brand`\n",
    "- Target encoding\n",
    "\n",
    "The engineered features will then be preprocessed into a form suitable for machine learning model:\n",
    "\n",
    "- Fill missing values\n",
    "- Encoding categorical features into integer values\n",
    "- Normalization of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.ops import LambdaOp\n",
    "\n",
    "# cross features\n",
    "def user_id_cross_maker(col, gdf):\n",
    "    return col.astype(str) + '_' + gdf['user_id'].astype(str)\n",
    "\n",
    "user_id_cross_features = (\n",
    "    nvt.ColumnGroup(['product_id', 'brand', 'ts_hour', 'ts_minute']) >>\n",
    "    LambdaOp(user_id_cross_maker, dependency=['user_id']) >> \n",
    "    nvt.ops.Rename(postfix = '_user_id_cross')\n",
    ")\n",
    "\n",
    "\n",
    "def user_id_brand_cross_maker(col, gdf):\n",
    "    return col.astype(str) + '_' + gdf['user_id'].astype(str) + '_' + gdf['brand'].astype(str)\n",
    "\n",
    "user_id_brand_cross_features = (\n",
    "    nvt.ColumnGroup(['ts_hour', 'ts_weekday', 'cat_0', 'cat_1', 'cat_2']) >>\n",
    "    LambdaOp(user_id_brand_cross_maker, dependency=['user_id', 'brand']) >> \n",
    "    nvt.ops.Rename(postfix = '_user_id_brand_cross')\n",
    ")\n",
    "\n",
    "target_encode = (\n",
    "    ['brand', 'user_id', 'product_id', 'cat_2', ['ts_weekday', 'ts_day']] >>\n",
    "    nvt.ops.TargetEncoding(\n",
    "        nvt.ColumnGroup('target'),\n",
    "        kfold=5,\n",
    "        p_smooth=20,\n",
    "        out_dtype=\"float32\",\n",
    "        )\n",
    ")\n",
    "\n",
    "cat_feats = (user_id_brand_cross_features + user_id_cross_features) >> nvt.ops.Categorify()\n",
    "cont_feats =  ['price', 'ts_weekday', 'ts_day', 'ts_month'] >> nvt.ops.FillMissing() >>  nvt.ops.Normalize()\n",
    "cont_feats += target_encode >> nvt.ops.Rename(postfix = '_TE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cat_feats + cont_feats + 'target'\n",
    "proc = nvt.Workflow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize workflow as a DAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "graphviz is already the newest version (2.42.2-3build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1880pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 1879.62 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 1875.62,-472 1875.62,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1058.98\" cy=\"-162\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1058.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"762.98\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"762.98\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1013.38,-150.22C954.09,-136.19 851.79,-112 798.14,-99.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"798.62,-95.83 788.09,-96.94 797.01,-102.64 798.62,-95.83\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1093.98\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>15&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1085.87,-216.76C1081.79,-208.61 1076.75,-198.53 1072.14,-189.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1075.15,-187.5 1067.54,-180.12 1068.89,-190.63 1075.15,-187.5\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1442.98\" cy=\"-450\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1442.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[product_id, brand, ts_hour...]</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1442.98\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1442.98\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;13 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>1&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1442.98,-431.7C1442.98,-423.98 1442.98,-414.71 1442.98,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1446.48,-406.1 1442.98,-396.1 1439.48,-406.1 1446.48,-406.1\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"194.98\" cy=\"-306\" rx=\"194.97\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[price, ts_weekday, ts_day...]</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"318.98\" cy=\"-234\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M225,-288.05C242.41,-278.22 264.46,-265.78 282.83,-255.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.79,-258.32 291.78,-250.36 281.35,-252.22 284.79,-258.32\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"472.98\" cy=\"-162\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"472.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.89,-218.5C374.48,-207.77 406.8,-193.08 432.25,-181.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"433.99,-184.57 441.64,-177.25 431.09,-178.2 433.99,-184.57\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"679.98\" cy=\"-234\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">TargetEncoding</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"679.98\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M679.98,-215.7C679.98,-207.98 679.98,-198.71 679.98,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"683.48,-190.1 679.98,-180.1 676.48,-190.1 683.48,-190.1\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"608.98\" cy=\"-306\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[brand, user_id, product_id...]</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>12&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M626.17,-288.05C635.07,-279.28 646.07,-268.43 655.81,-258.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"658.29,-261.3 662.95,-251.79 653.38,-256.32 658.29,-261.3\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"927.98\" cy=\"-306\" rx=\"99.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"927.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[target]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>8&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M876.6,-290.5C836.4,-279.15 780.5,-263.37 738.57,-251.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"739.35,-248.12 728.77,-248.77 737.44,-254.86 739.35,-248.12\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1093.98\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>5&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1093.98,-287.7C1093.98,-279.98 1093.98,-270.71 1093.98,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1097.48,-262.1 1093.98,-252.1 1090.48,-262.1 1097.48,-262.1\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1014.98\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1014.98\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>17&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1033.31,-360.76C1043.75,-351.51 1057,-339.77 1068.45,-329.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1070.87,-332.16 1076.03,-322.91 1066.23,-326.92 1070.87,-332.16\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;11 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M517.66,-150.22C575.6,-136.23 675.46,-112.13 728.13,-99.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"729.11,-102.78 738.01,-97.03 727.47,-95.97 729.11,-102.78\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M698.82,-145.12C710.67,-135.12 726.07,-122.13 738.82,-111.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"741.36,-113.82 746.74,-104.7 736.84,-108.47 741.36,-113.82\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"845.98\" cy=\"-162\" rx=\"99.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"845.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[target]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.89,-144.05C814.08,-134.1 799.09,-121.46 786.71,-111.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.91,-108.28 779,-104.51 784.39,-113.63 788.91,-108.28\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1766.98\" cy=\"-450\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1766.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[user_id]</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>10&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1704.51,-435.5C1645.62,-422.78 1558.07,-403.86 1500.76,-391.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1501.29,-388.02 1490.78,-389.33 1499.81,-394.86 1501.29,-388.02\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"762.98\" cy=\"-18\" rx=\"505.81\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"762.98\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols=[ts_hour_user_id_brand_cross, ts_weekday_user_id_brand_cross, cat_0_user_id_brand_cross...]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>11&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M762.98,-71.7C762.98,-63.98 762.98,-54.71 762.98,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"766.48,-46.1 762.98,-36.1 759.48,-46.1 766.48,-46.1\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1364.98\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1364.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1424.89,-360.76C1414.58,-351.51 1401.5,-339.77 1390.19,-329.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1392.49,-326.98 1382.71,-322.91 1387.81,-332.19 1392.49,-326.98\"/>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1326.44,-295.05C1273.54,-281.38 1179.21,-257.02 1128.5,-243.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1129.23,-240.49 1118.67,-241.38 1127.48,-247.27 1129.23,-240.49\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"579.98\" cy=\"-450\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"579.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[ts_hour, ts_weekday, cat_0...]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M673.03,-434.03C757.42,-420.45 879.47,-400.81 952.64,-389.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"953.31,-392.47 962.63,-387.42 952.2,-385.56 953.31,-392.47\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"903.98\" cy=\"-450\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"903.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[user_id]</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;17 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>19&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M930.29,-432.41C945.65,-422.72 965.18,-410.4 981.62,-400.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"983.8,-402.81 990.39,-394.51 980.06,-396.88 983.8,-402.81\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1124.98\" cy=\"-450\" rx=\"98.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1124.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[brand]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1099.19,-432.59C1083.98,-422.9 1064.56,-410.55 1048.2,-400.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.79,-397 1039.48,-394.59 1046.04,-402.91 1049.79,-397\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7effca7bc430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the workflow\n",
    "\n",
    "After having defined the workflow, calling the `fit()` method will start the actual computation to record the required statistics from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 9.04 s, total: 25.8 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_preproc_start = time()\n",
    "proc.fit(train_dataset)\n",
    "time_preproc = time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes = {}\n",
    "for col in cat_feats.columns:\n",
    "    dict_dtypes[col] = np.int64\n",
    "for col in cont_feats.columns:\n",
    "    dict_dtypes[col] = np.float32\n",
    "\n",
    "dict_dtypes['target'] = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the `transform()` method to transform the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_dir = os.path.join(output_path, 'train/')\n",
    "output_valid_dir = os.path.join(output_path, 'valid/')\n",
    "output_test_dir = os.path.join(output_path, 'test/')\n",
    "! rm -rf $output_train_dir && mkdir -p $output_train_dir\n",
    "! rm -rf $output_valid_dir && mkdir -p $output_valid_dir\n",
    "! rm -rf $output_test_dir && mkdir -p $output_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 2.19 s, total: 4.32 s\n",
      "Wall time: 9.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(train_dataset).to_parquet(output_path=output_train_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 692572\n",
      "-rw-r--r-- 1 nobody nogroup 706367943 Apr 27 06:22 0.1e6ee9653b994c808e2c40829e0563aa.parquet\n",
      "-rw-r--r-- 1 nobody nogroup        75 Apr 27 06:22 _file_list.txt\n",
      "-rw-r--r-- 1 nobody nogroup     21931 Apr 27 06:22 _metadata\n",
      "-rw-r--r-- 1 nobody nogroup      1073 Apr 27 06:22 _metadata.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l $output_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 1.32 s, total: 2.39 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(valid_dataset).to_parquet(output_path=output_valid_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 90716\n",
      "-rw-r--r-- 1 nobody nogroup 92502437 Apr 27 06:24 0.7a4194cbd9b54bb8a71a94d1fbe8f7c0.parquet\n",
      "-rw-r--r-- 1 nobody nogroup       75 Apr 27 06:24 _file_list.txt\n",
      "-rw-r--r-- 1 nobody nogroup    10351 Apr 27 06:24 _metadata\n",
      "-rw-r--r-- 1 nobody nogroup     1073 Apr 27 06:24 _metadata.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l $output_valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 1.36 s, total: 2.37 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(test_dataset).to_parquet(output_path=output_test_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.95477104187012"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the preprocessed data\n",
    "\n",
    "Let's quickly read the data back and verify that all fields have the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4018467</td>\n",
       "      <td>396848</td>\n",
       "      <td>20491</td>\n",
       "      <td>133169</td>\n",
       "      <td>0</td>\n",
       "      <td>2488907</td>\n",
       "      <td>807924</td>\n",
       "      <td>3630212</td>\n",
       "      <td>459548</td>\n",
       "      <td>-0.744645</td>\n",
       "      <td>-1.490397</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>1.314784</td>\n",
       "      <td>0.336722</td>\n",
       "      <td>0.382853</td>\n",
       "      <td>0.319044</td>\n",
       "      <td>-1.287531</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3114755</td>\n",
       "      <td>316652</td>\n",
       "      <td>1550601</td>\n",
       "      <td>2190065</td>\n",
       "      <td>918206</td>\n",
       "      <td>1796140</td>\n",
       "      <td>2109404</td>\n",
       "      <td>2816271</td>\n",
       "      <td>4600643</td>\n",
       "      <td>-0.334563</td>\n",
       "      <td>-1.490397</td>\n",
       "      <td>0.465993</td>\n",
       "      <td>-0.864342</td>\n",
       "      <td>0.466865</td>\n",
       "      <td>0.260187</td>\n",
       "      <td>0.500493</td>\n",
       "      <td>0.459758</td>\n",
       "      <td>0.400095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3459905</td>\n",
       "      <td>2688577</td>\n",
       "      <td>1846366</td>\n",
       "      <td>2482208</td>\n",
       "      <td>1198526</td>\n",
       "      <td>1936863</td>\n",
       "      <td>2924787</td>\n",
       "      <td>3127246</td>\n",
       "      <td>5811629</td>\n",
       "      <td>-0.161978</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>1.734028</td>\n",
       "      <td>-0.864342</td>\n",
       "      <td>0.364658</td>\n",
       "      <td>0.278772</td>\n",
       "      <td>0.389843</td>\n",
       "      <td>0.459709</td>\n",
       "      <td>0.174040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3469840</td>\n",
       "      <td>494526</td>\n",
       "      <td>2566100</td>\n",
       "      <td>1023972</td>\n",
       "      <td>156135</td>\n",
       "      <td>2536189</td>\n",
       "      <td>864908</td>\n",
       "      <td>3136224</td>\n",
       "      <td>5124707</td>\n",
       "      <td>-0.642086</td>\n",
       "      <td>-1.490397</td>\n",
       "      <td>-0.340939</td>\n",
       "      <td>-0.864342</td>\n",
       "      <td>0.188281</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.300156</td>\n",
       "      <td>0.257571</td>\n",
       "      <td>0.427836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341689</td>\n",
       "      <td>635844</td>\n",
       "      <td>61423</td>\n",
       "      <td>590499</td>\n",
       "      <td>0</td>\n",
       "      <td>2771037</td>\n",
       "      <td>1359948</td>\n",
       "      <td>307055</td>\n",
       "      <td>1392750</td>\n",
       "      <td>-0.389825</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>0.120165</td>\n",
       "      <td>1.314784</td>\n",
       "      <td>0.392119</td>\n",
       "      <td>0.303642</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>-1.287949</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                      4018467                          396848   \n",
       "1                      3114755                          316652   \n",
       "2                      3459905                         2688577   \n",
       "3                      3469840                          494526   \n",
       "4                       341689                          635844   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                      20491                     133169   \n",
       "1                    1550601                    2190065   \n",
       "2                    1846366                    2482208   \n",
       "3                    2566100                    1023972   \n",
       "4                      61423                     590499   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                          0                   2488907               807924   \n",
       "1                     918206                   1796140              2109404   \n",
       "2                    1198526                   1936863              2924787   \n",
       "3                     156135                   2536189               864908   \n",
       "4                          0                   2771037              1359948   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                3630212                   459548 -0.744645   -1.490397   \n",
       "1                2816271                  4600643 -0.334563   -1.490397   \n",
       "2                3127246                  5811629 -0.161978    0.486228   \n",
       "3                3136224                  5124707 -0.642086   -1.490397   \n",
       "4                 307055                  1392750 -0.389825   -0.996241   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0  0.811821  1.314784            0.336722              0.382853   \n",
       "1  0.465993 -0.864342            0.466865              0.260187   \n",
       "2  1.734028 -0.864342            0.364658              0.278772   \n",
       "3 -0.340939 -0.864342            0.188281              0.390281   \n",
       "4  0.120165  1.314784            0.392119              0.303642   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.319044           -1.287531   \n",
       "1                 0.500493            0.459758   \n",
       "2                 0.389843            0.459709   \n",
       "3                 0.300156            0.257571   \n",
       "4                 0.429204           -1.287949   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.419828     1.0  \n",
       "1                        0.400095     0.0  \n",
       "2                        0.174040     0.0  \n",
       "3                        0.427836     0.0  \n",
       "4                        0.382604     0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir)\n",
    "nvtdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1696011</td>\n",
       "      <td>2147309</td>\n",
       "      <td>2779667</td>\n",
       "      <td>1486257</td>\n",
       "      <td>491398</td>\n",
       "      <td>480483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-1.378423</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.446590</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.501226</td>\n",
       "      <td>0.459607</td>\n",
       "      <td>0.422593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.768232</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.314866</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>-1.287949</td>\n",
       "      <td>0.374942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823524</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>-0.340939</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.369318</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.290187</td>\n",
       "      <td>0.369508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.527826</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.466285</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.499063</td>\n",
       "      <td>0.383081</td>\n",
       "      <td>0.374942</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247903</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>0.927097</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.466352</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.514849</td>\n",
       "      <td>0.459691</td>\n",
       "      <td>0.414420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                            0                         1696011   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                    2147309                    2779667   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                    1486257                    491398               480483   \n",
       "1                          0                         0                    0   \n",
       "2                          0                         0                    0   \n",
       "3                          0                         0                    0   \n",
       "4                          0                         0                    0   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                      0                        0  0.389749   -0.502085   \n",
       "1                      0                        0 -0.768232   -0.502085   \n",
       "2                      0                        0 -0.823524    0.486228   \n",
       "3                      0                        0 -0.527826   -0.502085   \n",
       "4                      0                        0 -0.247903   -0.996241   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0 -1.378423 -0.468138            0.446590              0.390281   \n",
       "1 -0.571491 -0.468138            0.314866              0.390281   \n",
       "2 -0.340939 -0.468138            0.369318              0.390281   \n",
       "3 -0.571491 -0.468138            0.466285              0.390281   \n",
       "4  0.927097 -0.468138            0.466352              0.390281   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.501226            0.459607   \n",
       "1                 0.390281           -1.287949   \n",
       "2                 0.390281            0.290187   \n",
       "3                 0.499063            0.383081   \n",
       "4                 0.514849            0.459691   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.422593     0.0  \n",
       "1                        0.374942     0.0  \n",
       "2                        0.369508     0.0  \n",
       "3                        0.374942     1.0  \n",
       "4                        0.414420     0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvtdata_valid = pd.read_parquet(output_valid_dir)\n",
    "nvtdata_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359020"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nvtdata_valid['ts_hour_user_id_brand_cross']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2461719"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nvtdata_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedding size\n",
    "\n",
    "Next, we need to get the embedding size for the categorical variables. This is an important input for defining the embedding table size to be used by HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand_user_id_cross': (3009092, 512),\n",
       " 'cat_0_user_id_brand_cross': (2877223, 512),\n",
       " 'cat_1_user_id_brand_cross': (2890639, 512),\n",
       " 'cat_2_user_id_brand_cross': (2159304, 512),\n",
       " 'product_id_user_id_cross': (4398425, 512),\n",
       " 'ts_hour_user_id_brand_cross': (4427037, 512),\n",
       " 'ts_hour_user_id_cross': (3999369, 512),\n",
       " 'ts_minute_user_id_cross': (5931061, 512),\n",
       " 'ts_weekday_user_id_brand_cross': (3961156, 512)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ops.get_embedding_sizes(proc)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]\n"
     ]
    }
   ],
   "source": [
    "print([embeddings[x][0] for x in cat_feats.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ts_hour_user_id_brand_cross',\n",
       " 'ts_weekday_user_id_brand_cross',\n",
       " 'cat_0_user_id_brand_cross',\n",
       " 'cat_1_user_id_brand_cross',\n",
       " 'cat_2_user_id_brand_cross',\n",
       " 'product_id_user_id_cross',\n",
       " 'brand_user_id_cross',\n",
       " 'ts_hour_user_id_cross',\n",
       " 'ts_minute_user_id_cross']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size_str = \"{}\".format([embeddings[x][0] for x in cat_feats.columns])\n",
    "embedding_size_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_con_feates = len(cont_feats.columns)\n",
    "num_con_feates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'ts_weekday',\n",
       " 'ts_day',\n",
       " 'ts_month',\n",
       " 'TE_brand_target_TE',\n",
       " 'TE_user_id_target_TE',\n",
       " 'TE_product_id_target_TE',\n",
       " 'TE_cat_2_target_TE',\n",
       " 'TE_ts_weekday_ts_day_target_TE']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print([embeddings[x][0] for x in cat_feats.columns])\n",
    "print(len(cont_feats.columns))\n",
    "print(len(cat_feats.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll shutdown our Dask client from earlier to free up some memory so that we can share it with HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training Python script for HugeCTR\n",
    "\n",
    "HugeCTR model can be defined by Python API. The below Python script defines a DLRM model and specifies the training resources. \n",
    "\n",
    "Several parameters that need to be edited to match this dataset are:\n",
    "\n",
    "- `slot_size_array`: cadinalities for the categorical variables\n",
    "- `dense_dim`: number of dense features\n",
    "- `slot_num`: number of categorical variables\n",
    "\n",
    "The model graph can be saved into a JSON file by calling `model.graph_to_json`, which will be used for inference afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hugectr_dlrm_ecommerce.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hugectr_dlrm_ecommerce.py\n",
    "import hugectr\n",
    "from mpi4py import MPI\n",
    "solver = hugectr.CreateSolver(max_eval_batches = 2720,\n",
    "                              batchsize_eval = 16384,\n",
    "                              batchsize = 16384,\n",
    "                              lr = 0.1,\n",
    "                              warmup_steps = 8000,\n",
    "                              decay_start = 48000,\n",
    "                              decay_steps = 24000,\n",
    "                              vvgpu = [[0,1,2,3]],\n",
    "                              repeat_dataset = True,\n",
    "                              i64_input_key = True)\n",
    "reader = hugectr.DataReaderParams(data_reader_type = hugectr.DataReaderType_t.Parquet,\n",
    "                                  source = [\"./nvtabular_temp/output/train/_file_list.txt\"],\n",
    "                                  eval_source = \"./nvtabular_temp/output/valid/_file_list.txt\",\n",
    "                                  check_type = hugectr.Check_t.Non,\n",
    "                                  slot_size_array = [4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061])\n",
    "optimizer = hugectr.CreateOptimizer(optimizer_type = hugectr.Optimizer_t.SGD,\n",
    "                                    update_type = hugectr.Update_t.Local,\n",
    "                                    atomic_update = True)\n",
    "model = hugectr.Model(solver, reader, optimizer)\n",
    "model.add(hugectr.Input(label_dim = 1, label_name = \"label\",\n",
    "                        dense_dim = 9, dense_name = \"dense\",\n",
    "                        data_reader_sparse_param_array = \n",
    "                        [hugectr.DataReaderSparseParam(hugectr.DataReaderSparse_t.Distributed, 9, 1, 9)],\n",
    "                        sparse_names = [\"data1\"]))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash,\n",
    "                            max_vocabulary_size_per_gpu = 10000000,\n",
    "                            embedding_vec_size = 128,\n",
    "                            combiner = 0,\n",
    "                            sparse_embedding_name = \"sparse_embedding1\",\n",
    "                            bottom_name = \"data1\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dense\"],\n",
    "                            top_names = [\"fc1\"],\n",
    "                            num_output=512))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc1\"],\n",
    "                            top_names = [\"relu1\"]))                           \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu1\"],\n",
    "                            top_names = [\"fc2\"],\n",
    "                            num_output=256))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc2\"],\n",
    "                            top_names = [\"relu2\"]))                            \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu2\"],\n",
    "                            top_names = [\"fc3\"],\n",
    "                            num_output=128))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc3\"],\n",
    "                            top_names = [\"relu3\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Interaction,\n",
    "                            bottom_names = [\"relu3\",\"sparse_embedding1\"],\n",
    "                            top_names = [\"interaction1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"interaction1\"],\n",
    "                            top_names = [\"fc4\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc4\"],\n",
    "                            top_names = [\"relu4\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu4\"],\n",
    "                            top_names = [\"fc5\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc5\"],\n",
    "                            top_names = [\"relu5\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu5\"],\n",
    "                            top_names = [\"fc6\"],\n",
    "                            num_output=512))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc6\"],\n",
    "                            top_names = [\"relu6\"]))                               \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu6\"],\n",
    "                            top_names = [\"fc7\"],\n",
    "                            num_output=256))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc7\"],\n",
    "                            top_names = [\"relu7\"]))                                                                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu7\"],\n",
    "                            top_names = [\"fc8\"],\n",
    "                            num_output=1))                                                                                           \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.BinaryCrossEntropyLoss,\n",
    "                            bottom_names = [\"fc8\", \"label\"],\n",
    "                            top_names = [\"loss\"]))\n",
    "model.compile()\n",
    "model.summary()\n",
    "model.graph_to_json(graph_config_file = \"dlrm_ecommerce.json\")\n",
    "model.fit(max_iter = 12000, display = 1000, eval_interval = 3000, snapshot = 10000, snapshot_prefix = \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. HugeCTR training\n",
    "\n",
    "Now we are ready to train a DLRM model with HugeCTR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================Model Init=====================================================\n",
      "[28d08h49m47s][HUGECTR][INFO]: Global seed is 3640373122\n",
      "Device 0: A100-PCIE-40GB\n",
      "Device 1: A100-PCIE-40GB\n",
      "Device 2: A100-PCIE-40GB\n",
      "Device 3: A100-PCIE-40GB\n",
      "[28d08h49m52s][HUGECTR][INFO]: num of DataReader workers: 4\n",
      "[28d08h49m53s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[28d08h49m53s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[28d08h49m53s][HUGECTR][INFO]: Vocabulary size: 33653306\n",
      "[28d08h49m53s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=10000000\n",
      "===================================================Model Compile===================================================\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu0 start to init embedding\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu3 start to init embedding\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu2 start to init embedding\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu1 start to init embedding\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu3 init embedding done\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu2 init embedding done\n",
      "[28d08h51m00s][HUGECTR][INFO]: gpu1 init embedding done\n",
      "===================================================Model Summary===================================================\n",
      "Label                                   Dense                         Sparse                        \n",
      "label                                   dense                          data1                         \n",
      "(None, 1)                               (None, 9)                               \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Layer Type                              Input Name                    Output Name                   Output Shape                  \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "DistributedSlotSparseEmbeddingHash      data1                         sparse_embedding1             (None, 9, 128)                \n",
      "InnerProduct                            dense                         fc1                           (None, 512)                   \n",
      "ReLU                                    fc1                           relu1                         (None, 512)                   \n",
      "InnerProduct                            relu1                         fc2                           (None, 256)                   \n",
      "ReLU                                    fc2                           relu2                         (None, 256)                   \n",
      "InnerProduct                            relu2                         fc3                           (None, 128)                   \n",
      "ReLU                                    fc3                           relu3                         (None, 128)                   \n",
      "Interaction                             relu3,sparse_embedding1       interaction1                  (None, 174)                   \n",
      "InnerProduct                            interaction1                  fc4                           (None, 1024)                  \n",
      "ReLU                                    fc4                           relu4                         (None, 1024)                  \n",
      "InnerProduct                            relu4                         fc5                           (None, 1024)                  \n",
      "ReLU                                    fc5                           relu5                         (None, 1024)                  \n",
      "InnerProduct                            relu5                         fc6                           (None, 512)                   \n",
      "ReLU                                    fc6                           relu6                         (None, 512)                   \n",
      "InnerProduct                            relu6                         fc7                           (None, 256)                   \n",
      "ReLU                                    fc7                           relu7                         (None, 256)                   \n",
      "InnerProduct                            relu7                         fc8                           (None, 1)                     \n",
      "BinaryCrossEntropyLoss                  fc8,label                     loss                                                        \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "[28d80h51m00s][HUGECTR][INFO]: Save the model graph to dlrm_ecommerce.json, successful\n",
      "=====================================================Model Fit=====================================================\n",
      "[28d80h51m00s][HUGECTR][INFO]: Use non-epoch mode with number of iterations: 12000\n",
      "[28d80h51m00s][HUGECTR][INFO]: Training batchsize: 16384, evaluation batchsize: 16384\n",
      "[28d80h51m00s][HUGECTR][INFO]: Evaluation interval: 3000, snapshot interval: 10000\n",
      "[28d80h51m00s][HUGECTR][INFO]: Sparse embedding trainable: 1, dense network trainable: 1\n",
      "[28d80h51m00s][HUGECTR][INFO]: Use mixed precision: 0, scaler: 1.000000, use cuda graph: 1\n",
      "[28d80h51m00s][HUGECTR][INFO]: lr: 0.100000, warmup_steps: 8000, decay_start: 48000, decay_steps: 24000, decay_power: 2.000000, end_lr: 0.000000\n",
      "[28d80h51m00s][HUGECTR][INFO]: Training source file: ./nvtabular_temp/output/train/_file_list.txt\n",
      "[28d80h51m00s][HUGECTR][INFO]: Evaluation source file: ./nvtabular_temp/output/valid/_file_list.txt\n",
      "[28d80h51m24s][HUGECTR][INFO]: Iter: 1000 Time(1000 iters): 23.672096s Loss: 0.659505 lr:0.012512\n",
      "[28d80h51m47s][HUGECTR][INFO]: Iter: 2000 Time(1000 iters): 22.850172s Loss: 0.531595 lr:0.025013\n",
      "[28d80h52m70s][HUGECTR][INFO]: Iter: 3000 Time(1000 iters): 20.176961s Loss: 0.521909 lr:0.037512\n",
      "[28d80h52m51s][HUGECTR][INFO]: Evaluation, AUC: 0.651373\n",
      "[28d80h52m51s][HUGECTR][INFO]: Eval Time for 2720 iters: 44.419071s\n",
      "[28d80h53m12s][HUGECTR][INFO]: Iter: 4000 Time(1000 iters): 64.791044s Loss: 0.498580 lr:0.050012\n",
      "[28d80h53m32s][HUGECTR][INFO]: Iter: 5000 Time(1000 iters): 20.241736s Loss: 0.520667 lr:0.062513\n",
      "[28d80h53m52s][HUGECTR][INFO]: Iter: 6000 Time(1000 iters): 20.336424s Loss: 0.501511 lr:0.075013\n",
      "[28d80h54m36s][HUGECTR][INFO]: Evaluation, AUC: 0.647762\n",
      "[28d80h54m36s][HUGECTR][INFO]: Eval Time for 2720 iters: 43.316855s\n",
      "[28d80h54m56s][HUGECTR][INFO]: Iter: 7000 Time(1000 iters): 63.770504s Loss: 0.523840 lr:0.087513\n",
      "[28d80h55m16s][HUGECTR][INFO]: Iter: 8000 Time(1000 iters): 20.271603s Loss: 0.491016 lr:0.100000\n",
      "[28d80h55m36s][HUGECTR][INFO]: Iter: 9000 Time(1000 iters): 20.159285s Loss: 0.514026 lr:0.100000\n",
      "[28d80h56m20s][HUGECTR][INFO]: Evaluation, AUC: 0.644476\n",
      "[28d80h56m20s][HUGECTR][INFO]: Eval Time for 2720 iters: 43.897980s\n",
      "[28d80h56m40s][HUGECTR][INFO]: Iter: 10000 Time(1000 iters): 64.047921s Loss: 0.486661 lr:0.100000\n",
      "[28d80h56m46s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[28d80h56m46s][HUGECTR][INFO]: Rank0: Dump hash table from GPU1\n",
      "[28d80h56m46s][HUGECTR][INFO]: Rank0: Dump hash table from GPU2\n",
      "[28d80h56m46s][HUGECTR][INFO]: Rank0: Dump hash table from GPU3\n",
      "[28d80h56m49s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[28d80h56m51s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[28d80h56m53s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[28d80h56m56s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[28d80h56m57s][HUGECTR][INFO]: Done\n",
      "[28d80h59m51s][HUGECTR][INFO]: Dumping sparse weights to files, successful\n",
      "[28d80h59m51s][HUGECTR][INFO]: Dumping sparse optimzer states to files, successful\n",
      "[28d80h59m51s][HUGECTR][INFO]: Dumping dense weights to file, successful\n",
      "[28d80h59m51s][HUGECTR][INFO]: Dumping dense optimizer states to file, successful\n",
      "[28d80h59m51s][HUGECTR][INFO]: Dumping untrainable weights to file, successful\n",
      "[28d90h00m11s][HUGECTR][INFO]: Iter: 11000 Time(1000 iters): 210.777217s Loss: 0.524206 lr:0.100000\n"
     ]
    }
   ],
   "source": [
    "!python3 hugectr_dlrm_ecommerce.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. HugeCTR inference\n",
    "\n",
    "In this section, we will read the test dataset, and compute the AUC value. \n",
    "\n",
    "We will utilize the saved model graph in JSON format for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the inference session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from hugectr.inference import InferenceParams, CreateInferenceSession\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inference session\n",
    "inference_params = InferenceParams(model_name = \"dlrm\",\n",
    "                              max_batchsize = 4096,\n",
    "                              hit_rate_threshold = 0.6,\n",
    "                              dense_model_file = \"./_dense_10000.model\",\n",
    "                              sparse_model_files = [\"./0_sparse_10000.model\"],\n",
    "                              device_id = 0,\n",
    "                              use_gpu_embedding_cache = True,\n",
    "                              cache_size_percentage = 0.2,\n",
    "                              i64_input_key = True)\n",
    "inference_session = CreateInferenceSession(\"dlrm_ecommerce.json\", inference_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and prepare the data\n",
    "\n",
    "We first read the NVTabular processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319049</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>-0.686767</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.440491</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.468224</td>\n",
       "      <td>0.422464</td>\n",
       "      <td>0.424978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1801819</td>\n",
       "      <td>0.956150</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>0.581269</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.466540</td>\n",
       "      <td>0.312225</td>\n",
       "      <td>0.365177</td>\n",
       "      <td>0.397007</td>\n",
       "      <td>0.398268</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.736772</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>0.927097</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.327666</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.166392</td>\n",
       "      <td>0.256890</td>\n",
       "      <td>0.433862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.730462</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>1.388201</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.327666</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.283870</td>\n",
       "      <td>0.349459</td>\n",
       "      <td>0.432988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.634275</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>-0.686767</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.338922</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.394446</td>\n",
       "      <td>-1.287531</td>\n",
       "      <td>0.425214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                          0                         0                    0   \n",
       "1                          0                         0                    0   \n",
       "2                          0                         0                    0   \n",
       "3                          0                         0                    0   \n",
       "4                          0                         0                    0   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                      0                        0  0.319049    0.486228   \n",
       "1                      0                  1801819  0.956150   -0.996241   \n",
       "2                      0                        0 -0.736772    0.486228   \n",
       "3                      0                        0 -0.730462   -0.996241   \n",
       "4                      0                        0 -0.634275    0.486228   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0 -0.686767 -0.270035            0.440491              0.390281   \n",
       "1  0.581269 -0.270035            0.466540              0.312225   \n",
       "2  0.927097 -0.270035            0.327666              0.390281   \n",
       "3  1.388201 -0.270035            0.327666              0.390281   \n",
       "4 -0.686767 -0.270035            0.338922              0.390281   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.468224            0.422464   \n",
       "1                 0.365177            0.397007   \n",
       "2                 0.166392            0.256890   \n",
       "3                 0.283870            0.349459   \n",
       "4                 0.394446           -1.287531   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.424978     0.0  \n",
       "1                        0.398268     0.0  \n",
       "2                        0.433862     0.0  \n",
       "3                        0.432988     0.0  \n",
       "4                        0.425214     0.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nvtdata_test = pd.read_parquet('./nvtabular_temp/output/test')\n",
    "nvtdata_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_feats = ['price',\n",
    " 'ts_weekday',\n",
    " 'ts_day',\n",
    " 'ts_month',\n",
    " 'TE_brand_target_TE',\n",
    " 'TE_user_id_target_TE',\n",
    " 'TE_product_id_target_TE',\n",
    " 'TE_cat_2_target_TE',\n",
    " 'TE_ts_weekday_ts_day_target_TE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['ts_hour_user_id_brand_cross',\n",
    " 'ts_weekday_user_id_brand_cross',\n",
    " 'cat_0_user_id_brand_cross',\n",
    " 'cat_1_user_id_brand_cross',\n",
    " 'cat_2_user_id_brand_cross',\n",
    " 'product_id_user_id_cross',\n",
    " 'brand_user_id_cross',\n",
    " 'ts_hour_user_id_cross',\n",
    " 'ts_minute_user_id_cross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = [4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data to CSR format\n",
    "\n",
    "HugeCTR expects data in CSR format for inference. One important thing to note is that NVTabular requires categorical variables to occupy different integer ranges. For example, if there are 10 users and 10 items, then the users should be encoded in the 0-9 range, while items should be in the 10-19 range. NVTabular encodes both users and items in the 0-9 ranges.\n",
    "\n",
    "For this reason, we need to shift the keys of the categorical variable produced by NVTabular to comply with HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shift = np.insert(np.cumsum(emb_size), 0, 0)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = nvtdata_test[cat_feats].values + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_data = nvtdata_test[con_feats].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_batch(inference_session, dense_data_batch, cat_data_batch):\n",
    "    dense_features = list(dense_data_batch.flatten())\n",
    "    embedding_columns = list(cat_data_batch.flatten())\n",
    "    row_ptrs= list(range(0,len(embedding_columns)+1))\n",
    "    output = inference_session.predict(dense_features, embedding_columns, row_ptrs, True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to carry out inference on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "num_batches = (len(dense_data) // batch_size) + 1\n",
    "batch_idx = np.array_split(np.arange(len(dense_data)), num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 677/677 [00:10<00:00, 62.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels = []\n",
    "for batch_id in tqdm(batch_idx):\n",
    "    dense_data_batch = dense_data[batch_id]\n",
    "    cat_data_batch = cat_data[batch_id]\n",
    "    results = infer_batch(inference_session, dense_data_batch, cat_data_batch)\n",
    "    labels.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772486"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the test AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = nvtdata_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.552195329480219"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(ground_truth, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we have walked you through the process of preprocessing the data, train a DLRM model with HugeCTR, then carrying out inference with the HugeCTR Python interface. Try this workflow on your data and let us know your feedback.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
