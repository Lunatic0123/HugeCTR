{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HugeCTR Embedding  Plugin for TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HugeCTR is a recommender specific framework which is capable of distributed training across multiple GPUs and nodes for Click-Through-Rate (CTR) estimation. This notebook introduces a TensorFlow plugin for the HugeCTR embedding layer (hereafter **embedding_plugin**), where users may benefit from both the computational efficiency of the HugeCTR embedding layer and the ease of use of TensorFlow (hereafter TF).\n",
    "\n",
    "This notebook will introduce how to compile `embedding_plugin`, its correctness verification, a demo usage guide, and its API signatures. To try this notebook, we recommand yo use our `dev.tfplugin.Dockerfile` docker image by referring to the instructions on `notebooks/README.md#1-requirements`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build embedding_plugin ##\n",
    "**1.**<br>\n",
    "Embedding_plugin is a tool of HugeCTR. In order to use this this plugin, you have to compile HugeCTR first. For example, use these commands to compile HugeCTR. \n",
    "```shell\n",
    "$ cd hugectr\n",
    "$ mkdir -p build && cd build\n",
    "$ cmake -DCMAKE_BUILD_TYPE=Release -DSM=80 .. # target is NVIDIA A100\n",
    "$ make -j$(nproc)\n",
    "```\n",
    "After compiling, there will be a dynamic library in `lib/` directory. \n",
    "```shell\n",
    "$ ls lib/*embedding_plugin* -h\n",
    "```\n",
    "will give output like\n",
    "```shell\n",
    "lib/libembedding_plugin.so\n",
    "```\n",
    "\n",
    "**2.**<br>\n",
    "Like every custom op for TF, you have to load that dynamic library using TF in order to use embedding_plugin. You can directly import [hugectr.py](../tools/embedding_plugin/python/hugectr.py), where we prepare codes to load that dynamic library and wrap some operations for convenient useage, in your python script to use this embedding_plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of correctness ##\n",
    "In order to varify whether this plugin can get correct results, we can use some synthetic datas to do the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to clear all variables.\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow and some modules\n",
    "import tensorflow as tf\n",
    "# do not let TF allocate all GPU memory\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for dev in devices:\n",
    "    tf.config.experimental.set_memory_growth(dev, True)\n",
    "    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hugectr.py to use embedding_plugin ops\n",
    "import sys\n",
    "sys.path.append(\"../tools/embedding_plugin/python/\")\n",
    "import hugectr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init embedding table value:\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]\n",
      " [17. 18. 19. 20.]\n",
      " [21. 22. 23. 24.]\n",
      " [25. 26. 27. 28.]\n",
      " [29. 30. 31. 32.]]\n"
     ]
    }
   ],
   "source": [
    "# generate a random embedding table and show\n",
    "vocabulary_size = 8\n",
    "slot_num = 3\n",
    "embedding_vector_size = 4\n",
    "\n",
    "table = np.float32([i for i in range(1, vocabulary_size * embedding_vector_size + 1)]).reshape(vocabulary_size, embedding_vector_size)\n",
    "print(\"init embedding table value:\\n\", table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HugeCTR, the corresponding dense shape of input keys is `[batch_size, slot_num, max_nnz]`, and `0` is a valid key. Therefore `-1` is used to denote invalid keys which only occupy that position in correspoding dense keys matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dense shape of inputs keys: (4, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# generate random keys to lookup from embedding table.\n",
    "keys = np.array([[[0, -1],   # nnz = 1\n",
    "                  [1, -1],   # nnz = 1\n",
    "                  [2,  6]],  # nnz = 2\n",
    "                 \n",
    "                 [[0, -1],   # nnz = 1\n",
    "                  [1, -1],   # nnz = 1\n",
    "                  [-1, -1]], # nnz = 0\n",
    "                 \n",
    "                 [[0, -1],   # nnz = 1\n",
    "                  [1, -1],   # nnz = 1\n",
    "                  [6, -1]],  # nnz = 1\n",
    "                 \n",
    "                 [[0, -1],   # nnz = 1\n",
    "                  [1, -1],   # nnz = 1\n",
    "                  [2, -1]]], # nnz = 1\n",
    "                dtype=np.int64) \n",
    "print(\"the dense shape of inputs keys:\", keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_result:\n",
      " tf.Tensor(\n",
      "[[[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [34. 36. 38. 40.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [25. 26. 27. 28.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [ 9. 10. 11. 12.]]], shape=(4, 3, 4), dtype=float32)\n",
      "\n",
      "\n",
      "second forward_result:\n",
      " tf.Tensor(\n",
      "[[[ 0.90024936  1.9002494   2.9002495   3.9002495 ]\n",
      "  [ 4.9002495   5.9002495   6.9002495   7.9002495 ]\n",
      "  [33.800995   35.800995   37.800995   39.800995  ]]\n",
      "\n",
      " [[ 0.90024936  1.9002494   2.9002495   3.9002495 ]\n",
      "  [ 4.9002495   5.9002495   6.9002495   7.9002495 ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.90024936  1.9002494   2.9002495   3.9002495 ]\n",
      "  [ 4.9002495   5.9002495   6.9002495   7.9002495 ]\n",
      "  [24.900497   25.900497   26.900497   27.900497  ]]\n",
      "\n",
      " [[ 0.90024936  1.9002494   2.9002495   3.9002495 ]\n",
      "  [ 4.9002495   5.9002495   6.9002495   7.9002495 ]\n",
      "  [ 8.900497    9.900497   10.900497   11.900497  ]]], shape=(4, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# define a simple forward propagation and backward propagation with embedding_plugin\n",
    "# NOTE: cause hugectr.init can only be called once, if you want to run this cell multi-times, please restart the kernel.\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # hugectr embedding_plugin initialize\n",
    "    hugectr.init(visiable_gpus=[0], seed=123, key_type='int64', value_type='float', batch_size=4, batch_size_eval=4)\n",
    "    \n",
    "    # create a embedding_layer with embedding_plugin\n",
    "    embedding_name = hugectr.create_embedding(init_value=table, opt_hparams=[0.1, 0.9, 0.99, 1e-3], \n",
    "                                              name_='embedding_verification', \n",
    "                                              max_vocabulary_size_per_gpu=vocabulary_size,\n",
    "                                              slot_num=slot_num, embedding_vec_size=embedding_vector_size,\n",
    "                                              embedding_type='distributed', max_nnz=2)\n",
    "    \n",
    "    # convert dense input keys to SparseTensor\n",
    "    indices = tf.where(keys != -1)\n",
    "    values = tf.gather_nd(keys, indices)\n",
    "    \n",
    "    # create a Variable used in backward propagation\n",
    "    bp_trigger = tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32)\n",
    "    \n",
    "    # get forward result\n",
    "    forward_result = hugectr.fprop(embedding_name=embedding_name,\n",
    "                                   sparse_indices=indices, values=values, dense_shape=keys.shape,\n",
    "                                   output_type=tf.float32, is_training=True, bp_trigger=bp_trigger)\n",
    "    print(\"forward_result:\\n\", forward_result)\n",
    "    \n",
    "    # compute gradients & update params\n",
    "    grads = tape.gradient(forward_result, bp_trigger)\n",
    "    \n",
    "    # do second forward propagation to check whether embedding table is updated.\n",
    "    forward_2 = hugectr.fprop(embedding_name=embedding_name,\n",
    "                              sparse_indices=indices, values=values, dense_shape=keys.shape,\n",
    "                              output_type=tf.float32, is_training=True, bp_trigger=bp_trigger)\n",
    "    print(\"\\n\")\n",
    "    print(\"second forward_result:\\n\", forward_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf forward_result:\n",
      " tf.Tensor(\n",
      "[[[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [34. 36. 38. 40.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [25. 26. 27. 28.]]\n",
      "\n",
      " [[ 1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.]\n",
      "  [ 9. 10. 11. 12.]]], shape=(4, 3, 4), dtype=float32)\n",
      "\n",
      "\n",
      "tf second forward_result:\n",
      " tf.Tensor(\n",
      "[[[ 0.90024906  1.9002491   2.900249    3.900249  ]\n",
      "  [ 4.900249    5.900249    6.900249    7.900249  ]\n",
      "  [33.800995   35.800995   37.800995   39.800995  ]]\n",
      "\n",
      " [[ 0.90024906  1.9002491   2.900249    3.900249  ]\n",
      "  [ 4.900249    5.900249    6.900249    7.900249  ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.90024906  1.9002491   2.900249    3.900249  ]\n",
      "  [ 4.900249    5.900249    6.900249    7.900249  ]\n",
      "  [24.900497   25.900497   26.900497   27.900497  ]]\n",
      "\n",
      " [[ 0.90024906  1.9002491   2.900249    3.900249  ]\n",
      "  [ 4.900249    5.900249    6.900249    7.900249  ]\n",
      "  [ 8.900497    9.900497   10.900497   11.900497  ]]], shape=(4, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# similarly, use original tensorflow op to compare whether results are consistent.\n",
    "\n",
    "# define a tf embedding layer\n",
    "class EmbeddingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocabulary_size, embedding_vec_size,\n",
    "                init_value):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_vec_size = embedding_vec_size\n",
    "        self.init_value = init_value\n",
    "        \n",
    "    def build(self, _):\n",
    "        self.Var = self.add_weight(shape=(self.vocabulary_size, self.embedding_vec_size),\n",
    "                                         initializer=tf.constant_initializer(value=self.init_value))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup_sparse(self.Var, inputs, sp_weights=None, combiner=\"sum\")\n",
    "    \n",
    "with tf.GradientTape() as tape:\n",
    "    # reshape keys into [batch_size * slot_num, max_nnz]\n",
    "    reshape_keys = np.reshape(keys, newshape=(-1, keys.shape[-1]))\n",
    "    indices = tf.where(reshape_keys != -1)\n",
    "    values = tf.gather_nd(reshape_keys, indices)\n",
    "\n",
    "    # define a layer\n",
    "    tf_layer = EmbeddingLayer(vocabulary_size, embedding_vector_size, table)\n",
    "    \n",
    "    # wrap input keys components into a SparseTensor\n",
    "    sparse_tensor = tf.sparse.SparseTensor(indices, values, reshape_keys.shape)\n",
    "    \n",
    "    tf_forward = tf_layer(sparse_tensor)\n",
    "    print(\"tf forward_result:\\n\", tf.reshape(tf_forward, [keys.shape[0], keys.shape[1], tf_forward.shape[-1]]))\n",
    "    \n",
    "    # define an optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.99, epsilon=1e-3)\n",
    "    \n",
    "    # compute gradients & update params\n",
    "    grads = tape.gradient(tf_forward, tf_layer.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, tf_layer.trainable_weights))\n",
    "    \n",
    "    # do second forward propagation to check whether params are updated.\n",
    "    tf_forward_2 = tf_layer(sparse_tensor)\n",
    "    print(\"\\n\")\n",
    "    print(\"tf second forward_result:\\n\", tf.reshape(tf_forward_2, [keys.shape[0], keys.shape[1], tf_forward_2.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistent in first forward propagation? True\n",
      "Consistent in second forward propagation? True\n"
     ]
    }
   ],
   "source": [
    "# assert whether embedding_plugin's results are consistent with tensorflow original ops\n",
    "first_forward_consistent = np.allclose(forward_result.numpy(), \n",
    "                                tf.reshape(tf_forward, [keys.shape[0], keys.shape[1], tf_forward.shape[-1]]).numpy())\n",
    "print(\"Consistent in first forward propagation?\", first_forward_consistent)\n",
    "\n",
    "second_forwad_consistent = np.allclose(forward_2.numpy(), \n",
    "                                tf.reshape(tf_forward_2, [keys.shape[0], keys.shape[1], tf_forward_2.shape[-1]]))\n",
    "print(\"Consistent in second forward propagation?\", second_forwad_consistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from embedding_plugins and original TF ops are consistent in both first and second forward propagation, which means embedding_plugin can get the same forward result and do the same backward propagation as TF ops. Therefore, embedding_plugin can get correct results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFM demo ##\n",
    "Build demo model. In this notebook, TF 2.x is used to build DeepFM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models with embedding_plugin ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please restart kernel to run this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, import tensorflow and import plugin ops from hugectr.py\n",
    "import tensorflow as tf\n",
    "# do not let TF allocate all GPU memory\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for dev in devices:\n",
    "    tf.config.experimental.set_memory_growth(dev, True)\n",
    "import sys\n",
    "sys.path.append(\"../tools/embedding_plugin/python/\")\n",
    "import hugectr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap plugin ops into a TF layer for easy use\n",
    "class PluginEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 slot_num,\n",
    "                 embedding_vec_size,\n",
    "                 gpu_count,\n",
    "                 initializer=False,\n",
    "                 name='plugin_embedding',\n",
    "                 embedding_type='localized',\n",
    "                 optimizer='Adam',\n",
    "                 opt_hparam=[0.1, 0.9, 0.99, 1e-3],\n",
    "                 update_type='Local',\n",
    "                 atomic_update=True,\n",
    "                 max_feature_num=int(1e3),\n",
    "                 max_nnz=1,\n",
    "                 combiner='sum',\n",
    "                 ):\n",
    "        super(PluginEmbedding, self).__init__()\n",
    "\n",
    "        self.vocabulary_size_each_gpu = (vocabulary_size // gpu_count) + 1 \n",
    "        self.slot_num = slot_num\n",
    "        self.embedding_vec_size = embedding_vec_size\n",
    "        self.embedding_type = embedding_type\n",
    "        self.optimizer_type = optimizer\n",
    "        self.opt_hparam = opt_hparam\n",
    "        self.update_type = update_type\n",
    "        self.atomic_update = atomic_update\n",
    "        self.max_feature_num = max_feature_num\n",
    "        self.max_nnz = max_nnz\n",
    "        self.combiner = combiner\n",
    "        self.gpu_count = gpu_count\n",
    "\n",
    "        self.name_ = hugectr.create_embedding(initializer, name_=name, embedding_type=self.embedding_type, \n",
    "                                             optimizer_type=self.optimizer_type, \n",
    "                                             max_vocabulary_size_per_gpu=self.vocabulary_size_each_gpu,\n",
    "                                             opt_hparams=self.opt_hparam, update_type=self.update_type,\n",
    "                                             atomic_update=self.atomic_update, slot_num=self.slot_num,\n",
    "                                             max_nnz=self.max_nnz, max_feature_num=self.max_feature_num,\n",
    "                                             embedding_vec_size=self.embedding_vec_size, \n",
    "                                             combiner=self.combiner)\n",
    "\n",
    "    def build(self, _):\n",
    "        self.bp_trigger = self.add_weight(name=\"bp_trigger\",\n",
    "                                          shape=(1,), dtype=tf.float32, trainable=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, row_offsets, value_tensors, nnz_array, output_shape, training=False):\n",
    "        return hugectr.fprop_v3(embedding_name=self.name_, row_offsets=row_offsets, value_tensors=value_tensors, \n",
    "                                nnz_array=nnz_array, bp_trigger=self.bp_trigger, is_training=training,\n",
    "                                output_shape=output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define other TF layers\n",
    "class Multiply(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_units):\n",
    "        super(Multiply, self).__init__()\n",
    "        self.out_units = out_units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='weight_vector', shape=(input_shape[1], self.out_units),\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs * self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build DeepFM with plugin layer\n",
    "class DeepFM_PluginEmbedding(tf.keras.models.Model):\n",
    "    def __init__(self, \n",
    "                 vocabulary_size, \n",
    "                 embedding_vec_size,\n",
    "                 which_embedding,\n",
    "                 dropout_rate, # list of float\n",
    "                 deep_layers, # list of int\n",
    "                 initializer,\n",
    "                 gpus,\n",
    "                 batch_size,\n",
    "                 batch_size_eval,\n",
    "                 embedding_type = 'localized',\n",
    "                 slot_num=1,\n",
    "                 seed=123):\n",
    "        super(DeepFM_PluginEmbedding, self).__init__()\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_vec_size = embedding_vec_size\n",
    "        self.which_embedding = which_embedding\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.deep_layers = deep_layers\n",
    "        self.gpus = gpus\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_eval = batch_size_eval \n",
    "        self.slot_num = slot_num\n",
    "        self.embedding_type = embedding_type\n",
    "\n",
    "        if isinstance(initializer, str):\n",
    "            initializer = False\n",
    "            \n",
    "        # when building model with embedding_plugin ops, init() should be called prior to any other ops.\n",
    "        hugectr.init(visiable_gpus=gpus, seed=seed, key_type='int64', value_type='float', \n",
    "                        batch_size=batch_size, batch_size_eval=batch_size_eval)\n",
    "        \n",
    "        # create a embedding_plugin layer\n",
    "        self.plugin_embedding_layer = PluginEmbedding(vocabulary_size=vocabulary_size, slot_num=slot_num, \n",
    "                                            embedding_vec_size=embedding_vec_size + 1, \n",
    "                                            embedding_type=embedding_type,\n",
    "                                            gpu_count=len(gpus), initializer=initializer)\n",
    "        \n",
    "        # other layers with TF original ops\n",
    "        self.deep_dense = []\n",
    "        for i, deep_units in enumerate(self.deep_layers):\n",
    "            self.deep_dense.append(tf.keras.layers.Dense(units=deep_units, activation=None, use_bias=True,\n",
    "                                                         kernel_initializer='glorot_normal', \n",
    "                                                         bias_initializer='glorot_normal'))\n",
    "            self.deep_dense.append(tf.keras.layers.Dropout(dropout_rate[i]))\n",
    "        self.deep_dense.append(tf.keras.layers.Dense(units=1, activation=None, use_bias=True,\n",
    "                                                     kernel_initializer='glorot_normal',\n",
    "                                                     bias_initializer=tf.constant_initializer(0.01)))\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.y_act = tf.keras.layers.Activation(activation='sigmoid')\n",
    "\n",
    "        self.dense_multi = Multiply(1)\n",
    "        self.dense_embedding = Multiply(self.embedding_vec_size)\n",
    "\n",
    "        self.concat_1 = tf.keras.layers.Concatenate()\n",
    "        self.concat_2 = tf.keras.layers.Concatenate()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, dense_feature, sparse_feature, training=True):\n",
    "        \"\"\"\n",
    "        forward propagation.\n",
    "        #arguments:\n",
    "            dense_feature: [batch_size, dense_dim]\n",
    "            sparse_feature: for OriginalEmbedding, it is a SparseTensor, and the dense shape is [batch_size * slot_num, max_nnz];\n",
    "                            for PluginEmbedding, it is a list of [row_offsets, value_tensors, nnz_array]. \n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"embedding_and_slice\"):\n",
    "            dense_0 = tf.cast(tf.expand_dims(dense_feature, 2), dtype=tf.float32) # [batchsize, dense_dim, 1]\n",
    "            dense_mul = self.dense_multi(dense_0) # [batchsize, dense_dim, 1]\n",
    "            dense_emb = self.dense_embedding(dense_0) # [batchsize, dense_dim, embedding_vec_size]\n",
    "            dense_mul = tf.reshape(dense_mul, [dense_mul.shape[0], -1]) # [batchsize, dense_dim * 1]\n",
    "            dense_emb = tf.reshape(dense_emb, [dense_emb.shape[0], -1]) # [batchsize, dense_dim * embedding_vec_size]\n",
    "\n",
    "            sparse = self.plugin_embedding_layer(sparse_feature[0], sparse_feature[1], sparse_feature[2],\n",
    "                                                output_shape=[self.batch_size, self.slot_num, self.embedding_vec_size + 1],\n",
    "                                                training=training) # [batch_size, self.slot_num, self.embedding_vec_size + 1]\n",
    "\n",
    "            sparse_1 = tf.slice(sparse, [0, 0, self.embedding_vec_size], [-1, self.slot_num, 1]) #[batchsize, slot_num, 1]\n",
    "            sparse_1 = tf.squeeze(sparse_1, 2) # [batchsize, slot_num]\n",
    "\n",
    "            sparse_emb = tf.slice(sparse, [0, 0, 0], [-1, self.slot_num, self.embedding_vec_size]) #[batchsize, slot_num, embedding_vec_size]\n",
    "            sparse_emb = tf.reshape(sparse_emb, [-1, self.slot_num * self.embedding_vec_size]) #[batchsize, slot_num * embedding_vec_size]\n",
    "        \n",
    "        with tf.name_scope(\"FM\"):\n",
    "            with tf.name_scope(\"first_order\"):\n",
    "                first = self.concat_1([dense_mul, sparse_1]) # [batchsize, dense_dim + slot_num]\n",
    "                first_out = tf.reduce_sum(first, axis=-1, keepdims=True) # [batchsize, 1]\n",
    "                \n",
    "            with tf.name_scope(\"second_order\"):\n",
    "                hidden = self.concat_2([dense_emb, sparse_emb]) # [batchsize, (dense_dim + slot_num) * embedding_vec_size]\n",
    "                second = tf.reshape(hidden, [-1, dense_feature.shape[1] + self.slot_num, self.embedding_vec_size])\n",
    "                square_sum = tf.math.square(tf.math.reduce_sum(second, axis=1, keepdims=True)) # [batchsize, 1, embedding_vec_size]\n",
    "                sum_square = tf.math.reduce_sum(tf.math.square(second), axis=1, keepdims=True) # [batchsize, 1, embedding_vec_size]\n",
    "                \n",
    "                second_out = 0.5 * (sum_square - square_sum) # [batchsize, 1, embedding_vec_size]\n",
    "                second_out = tf.math.reduce_sum(second_out, axis=-1, keepdims=False) # [batchsize, 1]\n",
    "                \n",
    "        with tf.name_scope(\"Deep\"):\n",
    "            for i, layer in enumerate(self.deep_dense):\n",
    "                if i % 2 == 0: # dense\n",
    "                    hidden = layer(hidden)\n",
    "                else: # dropout\n",
    "                    hidden = layer(hidden, training)\n",
    "\n",
    "        y = self.add_layer([hidden, first_out, second_out])\n",
    "        y = self.y_act(y) # [batchsize, 1]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above cells wrap embedding_plugin ops into a TF layer, and uses that layer to define a TF DeepFM model. Similarly, define an embedding layer with TF original ops, and define a DeepFM model with that layer. Because embedding_plugin supports model parallelism, the parameters of original TF embedding layer are equally distributed to each GPU for a fair performance comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models with original TF ops ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TF embedding layer with TF original ops\n",
    "class OriginalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 vocabulary_size,\n",
    "                 embedding_vec_size,\n",
    "                 initializer='uniform',\n",
    "                 combiner=\"sum\",\n",
    "                 gpus=[0]):\n",
    "        super(OriginalEmbedding, self).__init__()\n",
    "\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_vec_size = embedding_vec_size \n",
    "        if isinstance(initializer, str):\n",
    "            self.initializer = tf.keras.initializers.get(initializer)\n",
    "        else:\n",
    "            self.initializer = initializer\n",
    "        if combiner not in [\"sum\", \"mean\"]:\n",
    "            raise RuntimeError(\"combiner must be one of \\{'sum', 'mean'\\}.\")\n",
    "        self.combiner = combiner\n",
    "        if (not isinstance(gpus, list)) and (not isinstance(gpus, tuple)):\n",
    "            raise RuntimeError(\"gpus must be a list or tuple.\")\n",
    "        self.gpus = gpus\n",
    "\n",
    "    def build(self, _):\n",
    "        if isinstance(self.initializer, tf.keras.initializers.Initializer):\n",
    "            if len(self.gpus) > 1:\n",
    "                self.embeddings_params = list()\n",
    "                mod_size = self.vocabulary_size % len(self.gpus)\n",
    "                vocabulary_size_each_gpu = [(self.vocabulary_size // len(self.gpus)) + (1 if dev_id < mod_size else 0)\n",
    "                                            for dev_id in range(len(self.gpus))]\n",
    "\n",
    "                for i, gpu in enumerate(self.gpus):\n",
    "                    with tf.device(\"/gpu:%d\" %gpu):\n",
    "                        params_i = self.add_weight(name=\"embedding_\" + str(gpu), \n",
    "                                                   shape=(vocabulary_size_each_gpu[i], self.embedding_vec_size),\n",
    "                                                   initializer=self.initializer)\n",
    "                    self.embeddings_params.append(params_i)\n",
    "\n",
    "            else:\n",
    "                self.embeddings_params = self.add_weight(name='embeddings', \n",
    "                                                        shape=(self.vocabulary_size, self.embedding_vec_size),\n",
    "                                                        initializer=self.initializer)\n",
    "        else:\n",
    "            self.embeddings_params = self.initializer\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, keys, output_shape):\n",
    "        result = tf.nn.embedding_lookup_sparse(self.embeddings_params, keys, \n",
    "                                             sp_weights=None, combiner=self.combiner)\n",
    "        return tf.reshape(result, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DeepFM model with original TF embedding layer\n",
    "class DeepFM_OriginalEmbedding(tf.keras.models.Model):\n",
    "    def __init__(self, \n",
    "                 vocabulary_size, \n",
    "                 embedding_vec_size,\n",
    "                 which_embedding,\n",
    "                 dropout_rate, # list of float\n",
    "                 deep_layers, # list of int\n",
    "                 initializer,\n",
    "                 gpus,\n",
    "                 batch_size,\n",
    "                 batch_size_eval,\n",
    "                 embedding_type = 'localized',\n",
    "                 slot_num=1,\n",
    "                 seed=123):\n",
    "        super(DeepFM_OriginalEmbedding, self).__init__()\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_vec_size = embedding_vec_size\n",
    "        self.which_embedding = which_embedding\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.deep_layers = deep_layers\n",
    "        self.gpus = gpus\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_eval = batch_size_eval \n",
    "        self.slot_num = slot_num\n",
    "        self.embedding_type = embedding_type\n",
    "\n",
    "        self.original_embedding_layer = OriginalEmbedding(vocabulary_size=vocabulary_size, \n",
    "                                            embedding_vec_size=embedding_vec_size + 1, \n",
    "                                            initializer=initializer, gpus=gpus)\n",
    "        self.deep_dense = []\n",
    "        for i, deep_units in enumerate(self.deep_layers):\n",
    "            self.deep_dense.append(tf.keras.layers.Dense(units=deep_units, activation=None, use_bias=True,\n",
    "                                                         kernel_initializer='glorot_normal', \n",
    "                                                         bias_initializer='glorot_normal'))\n",
    "            self.deep_dense.append(tf.keras.layers.Dropout(dropout_rate[i]))\n",
    "        self.deep_dense.append(tf.keras.layers.Dense(units=1, activation=None, use_bias=True,\n",
    "                                                     kernel_initializer='glorot_normal',\n",
    "                                                     bias_initializer=tf.constant_initializer(0.01)))\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.y_act = tf.keras.layers.Activation(activation='sigmoid')\n",
    "\n",
    "        self.dense_multi = Multiply(1)\n",
    "        self.dense_embedding = Multiply(self.embedding_vec_size)\n",
    "\n",
    "        self.concat_1 = tf.keras.layers.Concatenate()\n",
    "        self.concat_2 = tf.keras.layers.Concatenate()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, dense_feature, sparse_feature, training=True):\n",
    "        \"\"\"\n",
    "        forward propagation.\n",
    "        #arguments:\n",
    "            dense_feature: [batch_size, dense_dim]\n",
    "            sparse_feature: for OriginalEmbedding, it is a SparseTensor, and the dense shape is [batch_size * slot_num, max_nnz];\n",
    "                            for PluginEmbedding, it is a list of [row_offsets, value_tensors, nnz_array]. \n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"embedding_and_slice\"):\n",
    "            dense_0 = tf.cast(tf.expand_dims(dense_feature, 2), dtype=tf.float32) # [batchsize, dense_dim, 1]\n",
    "            dense_mul = self.dense_multi(dense_0) # [batchsize, dense_dim, 1]\n",
    "            dense_emb = self.dense_embedding(dense_0) # [batchsize, dense_dim, embedding_vec_size]\n",
    "            dense_mul = tf.reshape(dense_mul, [dense_mul.shape[0], -1]) # [batchsize, dense_dim * 1]\n",
    "            dense_emb = tf.reshape(dense_emb, [dense_emb.shape[0], -1]) # [batchsize, dense_dim * embedding_vec_size]\n",
    "\n",
    "            sparse = self.original_embedding_layer(sparse_feature, output_shape=[-1, self.slot_num, self.embedding_vec_size + 1])\n",
    "\n",
    "            sparse_1 = tf.slice(sparse, [0, 0, self.embedding_vec_size], [-1, self.slot_num, 1]) #[batchsize, slot_num, 1]\n",
    "            sparse_1 = tf.squeeze(sparse_1, 2) # [batchsize, slot_num]\n",
    "\n",
    "            sparse_emb = tf.slice(sparse, [0, 0, 0], [-1, self.slot_num, self.embedding_vec_size]) #[batchsize, slot_num, embedding_vec_size]\n",
    "            sparse_emb = tf.reshape(sparse_emb, [-1, self.slot_num * self.embedding_vec_size]) #[batchsize, slot_num * embedding_vec_size]\n",
    "        \n",
    "        with tf.name_scope(\"FM\"):\n",
    "            with tf.name_scope(\"first_order\"):\n",
    "                first = self.concat_1([dense_mul, sparse_1]) # [batchsize, dense_dim + slot_num]\n",
    "                first_out = tf.reduce_sum(first, axis=-1, keepdims=True) # [batchsize, 1]\n",
    "                \n",
    "            with tf.name_scope(\"second_order\"):\n",
    "                hidden = self.concat_2([dense_emb, sparse_emb]) # [batchsize, (dense_dim + slot_num) * embedding_vec_size]\n",
    "                second = tf.reshape(hidden, [-1, dense_feature.shape[1] + self.slot_num, self.embedding_vec_size])\n",
    "                square_sum = tf.math.square(tf.math.reduce_sum(second, axis=1, keepdims=True)) # [batchsize, 1, embedding_vec_size]\n",
    "                sum_square = tf.math.reduce_sum(tf.math.square(second), axis=1, keepdims=True) # [batchsize, 1, embedding_vec_size]\n",
    "                \n",
    "                second_out = 0.5 * (sum_square - square_sum) # [batchsize, 1, embedding_vec_size]\n",
    "                second_out = tf.math.reduce_sum(second_out, axis=-1, keepdims=False) # [batchsize, 1]\n",
    "                \n",
    "        with tf.name_scope(\"Deep\"):\n",
    "            for i, layer in enumerate(self.deep_dense):\n",
    "                if i % 2 == 0: # dense\n",
    "                    hidden = layer(hidden)\n",
    "                else: # dropout\n",
    "                    hidden = layer(hidden, training)\n",
    "\n",
    "        y = self.add_layer([hidden, first_out, second_out])\n",
    "        y = self.y_act(y) # [batchsize, 1]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is needed to use these models for training.\n",
    "\n",
    "[Kaggle Criteo datasets](http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/) provided by CriteoLabs is used as the training dataset. The original training set contains 45,840,617 examples. Each example contains a label (1 if the ad was clicked, otherwise 0) and 39 features (13 integer features and 26 categorial features). \n",
    "\n",
    "Because TFRecord is suitable for training process and criteo dataset also has signigicant amounts of missing values across the feature columns, preprocessing is needed. The original test set doesn't containe labels, so it is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset processing ###\n",
    "1. Download dataset from [Kaggle Criteo datasets](http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/).\n",
    "2. Extract dataset. \n",
    "    ```shell\n",
    "    $ tar zxvf dac.tar.gz\n",
    "    ```\n",
    "3. Preprocess dataset, fill missing values. Preprocessing functions are defined in [preprocess.py](../tools/embedding_plugin/performance_profile/preprocess.py). Open that file, then you can check the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify source csv name and output csv name, run this command will do the preprocessing.\n",
    "# Warning: this command will take serveral hours to do preprocessing.\n",
    "%run ../tools/embedding_plugin/performance_profile/preprocess.py \\\n",
    "    --src_csv_path=train.txt --dst_csv_path=train.out.txt \\\n",
    "    --normalize_dense=0 --feature_cross=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split dataset into train, val, test\n",
    "```shell\n",
    "$ head -n 36672493 train.out.txt > train\n",
    "$ tail -n 9168124 train.out.txt > valtest\n",
    "$ head -n 4584062 valtest > val\n",
    "$ tail -n 4584062 valtest > test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert dataset into TFRecord file. Converting functions are defined in [txt2tfrecord.py](../tools/embedding_plugin/performance_profile/txt2tfrecord.py). Open that file, then you can check the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify source name and output tfrecord name, run this command will do the converting.\n",
    "# Warning: this command will take half an hour to do converting.\n",
    "%run ../tools/embedding_plugin/performance_profile/txt2tfrecord.py \\\n",
    "    --src_txt_name=train --dst_tfrecord_name=train.tfrecord \\\n",
    "    --normalized=0 --use_multi_process=1 --shard_num=1 \n",
    "    # if multi tfrecord files are wanted, set shard_num to the number of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data preprocessing, `*.tfrecord` file(s) will be generated, which can be used for training. Then training loop can be defined to use dataset and models to do the trianing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training loop and do training ###\n",
    "In [read_data.py](../tools/embedding_plugin/performance_profile/read_data.py), some functions about preprocessing and creating TF data reading pipeline are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env path, so that some modules can be imported\n",
    "sys.path.append(\"../tools/embedding_plugin/performance_profile/\")\n",
    "\n",
    "import txt2tfrecord as utils\n",
    "from read_data import create_dataset\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s')\n",
    "logging.root.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin\n"
     ]
    }
   ],
   "source": [
    "# choose wich model for training\n",
    "which_model = input().strip()\n",
    "if which_model not in [\"Original\", \"Plugin\"]:\n",
    "    raise RuntimeError(\"Input just can be one of {'Original', 'Plugin'}, not \", which_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some hyper parameters for training process\n",
    "if (\"Plugin\" == which_model):\n",
    "    batch_size = 16384\n",
    "    n_epochs = 1\n",
    "    distribute_keys = 1 \n",
    "    gpus = [0] # use GPU0\n",
    "    embedding_type = 'distributed'\n",
    "    vocabulary_size = 1737710\n",
    "    embedding_vec_size = 10\n",
    "    slot_num = 26\n",
    "    batch_size_eval = 1 * len(gpus)\n",
    "    \n",
    "elif (\"Original\" == which_model):\n",
    "    batch_size = 16384\n",
    "    n_epochs = 1\n",
    "    distribute_keys = 0\n",
    "    gpus = [0] # use GPU0\n",
    "    vocabulary_size = 1737710\n",
    "    embedding_vec_size = 10\n",
    "    slot_num = 26\n",
    "    batch_size_eval = 1 * len(gpus)\n",
    "    embedding_type = 'distributed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature_description to read tfrecord examples.\n",
    "cols = [utils.idx2key(idx, False) for idx in range(0, utils.NUM_TOTAL_COLUMNS)]\n",
    "feature_desc = dict()\n",
    "for col in cols:\n",
    "    if col == 'label' or col.startswith(\"I\"):\n",
    "        feature_desc[col] = tf.io.FixedLenFeature([], tf.int64) # scaler\n",
    "    else: \n",
    "        feature_desc[col] = tf.io.FixedLenFeature([1], tf.int64) # [slot_num, nnz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set data_path to your tfrecord\n",
    "data_path = \"../tools/embedding_plugin/performance_profile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfrecord reading pipeling\n",
    "dataset_names = [data_path + \"./train.tfrecord\"]\n",
    "dataset = create_dataset(dataset_names=dataset_names,\n",
    "                         feature_desc=feature_desc,\n",
    "                         batch_size=batch_size,\n",
    "                         n_epochs=n_epochs,\n",
    "                         distribute_keys=tf.constant(distribute_keys != 0, dtype=tf.bool),\n",
    "                         gpu_count=len(gpus),\n",
    "                         embedding_type=tf.constant(embedding_type, dtype=tf.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer used in other TF layers.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instance\n",
    "if \"Original\" == which_model:\n",
    "    model = DeepFM_OriginalEmbedding(vocabulary_size=vocabulary_size, embedding_vec_size=embedding_vec_size, \n",
    "                       which_embedding=which_model, embedding_type=embedding_type,\n",
    "                       dropout_rate=[0.5] * 10, deep_layers=[1024] * 10,\n",
    "                       initializer='uniform', gpus=gpus, batch_size=batch_size, batch_size_eval=batch_size_eval,\n",
    "                       slot_num=slot_num)\n",
    "elif \"Plugin\" == which_model:\n",
    "    model = DeepFM_PluginEmbedding(vocabulary_size=vocabulary_size, embedding_vec_size=embedding_vec_size, \n",
    "                       which_embedding=which_model, embedding_type=embedding_type,\n",
    "                       dropout_rate=[0.5] * 10, deep_layers=[1024] * 10,\n",
    "                       initializer='uniform', gpus=gpus, batch_size=batch_size, batch_size_eval=batch_size_eval,\n",
    "                       slot_num=slot_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training step\n",
    "@tf.function\n",
    "def _train_step(dense_batch, sparse_batch, y_batch, model, loss_fn, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_batch = tf.cast(y_batch, dtype=tf.float32)\n",
    "        logits = model(dense_batch, sparse_batch, training=True)\n",
    "        loss = loss_fn(y_batch, logits)\n",
    "        loss /= dense_batch.shape[0]\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-09 10:56:37,112 begin to train\n",
      "2020-11-09 10:56:48,639 step: 100, loss: 0.0002327, elapsed time: 11.52572 seconds.\n",
      "2020-11-09 10:56:58,390 step: 200, loss: 0.0002407, elapsed time: 9.75147 seconds.\n",
      "2020-11-09 10:57:08,186 step: 300, loss: 0.0002294, elapsed time: 9.79530 seconds.\n",
      "2020-11-09 10:57:18,039 step: 400, loss: 0.0002357, elapsed time: 9.85300 seconds.\n",
      "2020-11-09 10:57:27,925 step: 500, loss: 0.0002274, elapsed time: 9.88649 seconds.\n",
      "2020-11-09 10:57:37,838 step: 600, loss: 0.0002451, elapsed time: 9.91273 seconds.\n",
      "2020-11-09 10:57:47,798 step: 700, loss: 0.0002377, elapsed time: 9.96021 seconds.\n",
      "2020-11-09 10:57:57,771 step: 800, loss: 0.0002616, elapsed time: 9.97256 seconds.\n",
      "2020-11-09 10:58:07,755 step: 900, loss: 0.0002389, elapsed time: 9.98443 seconds.\n",
      "2020-11-09 10:58:17,763 step: 1000, loss: 0.0002417, elapsed time: 10.00777 seconds.\n",
      "2020-11-09 10:58:27,779 step: 1100, loss: 0.0002353, elapsed time: 10.01599 seconds.\n",
      "2020-11-09 10:58:37,819 step: 1200, loss: 0.0002564, elapsed time: 10.04043 seconds.\n",
      "2020-11-09 10:58:47,880 step: 1300, loss: 0.0002330, elapsed time: 10.06093 seconds.\n",
      "2020-11-09 10:58:57,958 step: 1400, loss: 0.0002431, elapsed time: 10.07743 seconds.\n",
      "2020-11-09 10:59:08,041 step: 1500, loss: 0.0002316, elapsed time: 10.08309 seconds.\n",
      "2020-11-09 10:59:18,197 step: 1600, loss: 0.0002264, elapsed time: 10.15631 seconds.\n",
      "2020-11-09 10:59:28,412 step: 1700, loss: 0.0002486, elapsed time: 10.21552 seconds.\n",
      "2020-11-09 10:59:38,599 step: 1800, loss: 0.0002532, elapsed time: 10.18646 seconds.\n",
      "2020-11-09 10:59:48,812 step: 1900, loss: 0.0002483, elapsed time: 10.21356 seconds.\n",
      "2020-11-09 10:59:59,044 step: 2000, loss: 0.0002438, elapsed time: 10.23115 seconds.\n",
      "2020-11-09 11:00:09,286 step: 2100, loss: 0.0002512, elapsed time: 10.24196 seconds.\n",
      "2020-11-09 11:00:19,515 step: 2200, loss: 0.0002501, elapsed time: 10.22941 seconds.\n",
      "2020-11-09 11:00:23,265 Train End. Elapsed Time: 226.152 seconds.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "logging.info(\"begin to train\")\n",
    "begin_time = time.time()\n",
    "display_begin = begin_time\n",
    "for step, datas in enumerate(dataset):\n",
    "    label, dense, others = datas[0], datas[1], datas[2:]\n",
    "    if tf.constant(distribute_keys != 0, dtype=tf.bool):\n",
    "        sparse = others[0:3]\n",
    "    else:\n",
    "        sparse = others[-1]\n",
    "    \n",
    "    train_loss = _train_step(dense, sparse, label, model, loss_fn, optimizer)\n",
    "    loss_value = train_loss.numpy()\n",
    "    \n",
    "    if (step % 100 == 0 and step != 0):\n",
    "        display_end = time.time()\n",
    "        logging.info(\"step: %d, loss: %.7f, elapsed time: %.5f seconds.\" %(step, loss_value, (display_end - display_begin)))\n",
    "        display_begin = display_end\n",
    "        \n",
    "end_time = time.time()\n",
    "logging.info(\"Train End. Elapsed Time: %.3f seconds.\" %(end_time - begin_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API signature ##\n",
    "All embedding_plugin related APIs are defined in [hugectr.py](../tools/embedding_plugin/python/hugectr.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  init(visiable_gpus, seed=0, key_type='int64', value_type='float', batch_size=1, batch_size_eval=1)\n",
    "  ```\n",
    "\n",
    "This function is used to create resource manager which manages resources used by embedding_plugin. <br>\n",
    "**IMPORTANT:** This function can only be called once, and must be prior to any other embedding_plugin APIs. And currently, only `key_type='int64', value_type='float'` is tested.\n",
    "\n",
    "| Args ||\n",
    "| :-----| :---- |\n",
    "| visiable_gpus | list of integers, used to specify which gpus will be used by embedding_plugin. |\n",
    "| seed | integer, the initializer random seed for embedding_plugin. |\n",
    "| key_type| string, can be one of {'uint32', 'int64'}. Used to specify the input keys data type. |\n",
    "| value_type| string, can be one of {'float', 'half'}. Used to specify the data type of embedding_plugin forward result. |\n",
    "| batch_size| integer, batch_size used in training process. |\n",
    "| batch_size_eval| integer, batch_size used in evaluation process. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  embedding_name = create_embedding(init_value, name_='hugectr_embedding', embedding_type='localized',\n",
    "                                     optimizer_type='Adam', max_vocabulary_size_per_gpu=1, slot_size_array=[],\n",
    "                                     opt_hparams=[0.001], update_type='Local', atomic_update=true, scaler=1.0,\n",
    "                                     slot_num=1, max_nnz=1, max_feature_num=1000000, embedding_vec_size=1,\n",
    "                                     combiner='sum')\n",
    "  ```\n",
    "  \n",
    "| Args ||\n",
    "| :-----| :---- |\n",
    "|init_value| can be a `bool` or a 2-D matrix with `dtype=tf.float32`. When it is `bool`, parameters will be randomly initialized. When it is a 2-D matrix with `dtype=tf.float32`, that matrix will be used to initialize parameters, and the matrix's row-index will be deemed to be key of the embedding table.|\n",
    "|name_|string, the name of this embedding layer. If `name_` is unique, then it will be used as the embedding layer name, otherwise, numerical suffix will be automatically added to `name_` to form an unique name for this embedding layer. |\n",
    "|embedding_type| string, can be one of {'localized', 'distributed'}. |\n",
    "| optimizer_type| string, can be one of {'Adam', 'MomentumSGD', 'Nesterov', 'SGD'}. | \n",
    "|max_vocabulary_size_per_gpu| integer, used to allocate GPU memory spaces for embedding layer.|\n",
    "|slot_size_array| list of integers, used to allocate GPU memory spaces precisely for embedding layer.|\n",
    "|opt_hparams| list of floats, used to specify hyper parameters for optimizer.<br>For `Adam`, `opt_hparams` must be a list of `[learning_rate, beta1, beta2, epsilon]`.<br>For `MomentumSGD`, `opt_hparams` must be a list of `[learning_rate, momentum_factor]`.<br>For `Nesterov`, `opt_hparams` must be a list of `[learning_rate, momentum_factor]`.<br>For `SGD`, `opt_hparams` must be a list of `[learning_rate]`.|\n",
    "|update_type| string, can be one of {'Local', 'Global', 'LazyGlobal'}. |\n",
    "|atomic_update| bool, only used in `SGD` optimizer. |\n",
    "|scaler| float, can be one of {1.0, 128.0, 256.0, 512.0, 1024.0}, used in `mixed_precission` training. |\n",
    "|slot_num| integer, how many slots (feature-fields) are unified in a single embedding layer. |\n",
    "|max_nnz| integer, the number of valid keys in a single slot.|\n",
    "|max_feature_num| integer, the number of valid keys in a single input sample.|\n",
    "|embedding_vec_size| integer, the embedding vector size of this embedding layer.|\n",
    "|combier|string, can be one of {'mean', 'sum'}. specify how to combine different embedding vector in the same slot.|\n",
    "\n",
    "|Returns||\n",
    "|:----| :---- |\n",
    "|embedding_name| tf.Tensor, dtype=tf.string. An unique name for this embedding layer.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  forward_result = fprop(sparse_indices, values, dense_shape, embedding_name, \n",
    "                         bp_trigger, output_type, is_training=True)\n",
    "  ```\n",
    "  \n",
    "This function can be used to do forward propagation for `distributed` and `localized` embedding layer. It take all inputs keys which are stored in SparseTensor format as its input, and will convert those keys to CSR format inside this function. Therefore its performance is not very satisfying.\n",
    "  \n",
    "|Args||\n",
    "|:----| :---- |\n",
    "|sparse_indices| A 2-D int64 tensor of shape [N, 3], which specifies the indices of the elements in the sparse tensor that contain valid values. And `N` represents how many valid values in the corresponding dense tensor, 3 represent valid values' [batch_idx, slot_idx, nnz_idx].|\n",
    "|values| A 1-D tensor of type specified in `init().key_type` ans shape [N], which supplies the valid values for each element in `sparse_indices`.|\n",
    "|dense_shape| A 1-D int64 tensor of shape [3], which specifies the dense_shape: `[batch_size, slot_num, max_nnz]` of the sparse tensor.|\n",
    "| embedding_name| tf.Tensor with `dtype=tf.string`, use which embedding layer to do forward propagation.|\n",
    "| bp_trigger| tf.Variable(dtype=tf.float32), used to automatically trigger back propagation of the embedding layer.|\n",
    "| output_type| should be the same with `init().value_type`.|\n",
    "| is_training| bool, specify whether use `training` resources or `evaluation` resources.|\n",
    "\n",
    "|Returns||\n",
    "|:----| :---- |\n",
    "|forward_result| tf.Tensor with `dtype=output_type`. Forward propagation results.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  forward_result = fprop_v3(embedding_name, row_offsets, value_tensors, nnz_array, \n",
    "                            bp_trigger, output_shape, is_training=True)\n",
    "  ```\n",
    "  \n",
    "This function can be used to do forward propagation for `distributed` and `localized` embedding layer. Its inputs has been previously converted to CSR format. Therefore no conversion will be conducted inside this function. For example, if `embedding_plugin` use 4 GPU to do computation, then 4 CSR sparse matrix will be needed as its inputs. And 4 `row_offsets` are stacked together to form a single tensor, so does `value_tensors`. \n",
    "\n",
    "|Args||\n",
    "|:----| :---- |\n",
    "|embedding_name| tf.Tensor with `dtype=tf.string`, use which embedding layer to do forward propgation.|\n",
    "|row_offsets| 2-D matrix with shape `[gpu_count, batch_size * slot_num + 1]`, `dtype=tf.int64`. Each row in this tensor denotes a CSR `row_offsets` for one GPU.|\n",
    "|value_tensors| 2-D matrix with shape `[gpu_count, keys_nums_in_a_batch]`, `dtype=tf.int64`. Each row in this tensor denotes a CSR `values` for one GPU.|\n",
    "|nnz_array| 1-D tensor with `dtype=tf.int64`, its length is equal to `gpu_count`, and each value denotes how many valid input keys in one CSR sparse matrix.| \n",
    "| bp_trigger| tf.Variable(dtype=tf.float32), used to automatically trigger back propagation of the embedding layer.|\n",
    "| output_shape| 1-D tensor, and its value should be `[batch_size, slot_num, embedding_vec_size]`.|\n",
    "| is_training| bool, specify whether use `training` resources or `evaluation` resources.|\n",
    "\n",
    "|Returns||\n",
    "|:----| :---- |\n",
    "|forward_result| tf.Tensor with `dtype=init().value_type`. Forward propagation result.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  save(embedding_name, save_name)\n",
    "  ```\n",
    "\n",
    "This function is used to save `embedding_plugin` parameters to file.\n",
    "\n",
    "|Args||\n",
    "|:----| :---- |\n",
    "|embedding_name| tf.Tensor with `dtype=tf.string`, save which embedding layer's parameter to file.|\n",
    "|save_name| string, the name of saved parameters.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ```python\n",
    "  restore(embedding_name, file_name)\n",
    "  ```\n",
    "  \n",
    "This function is used to restore `embedding_plugin` parameters from file.\n",
    "\n",
    "|Args||\n",
    "|:----| :---- |\n",
    "|embedding_name| tf.Tensor with `dtype=tf.string`, restore parameters for which embedding layer.|\n",
    "|file_name| string, restore paramters from this file. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
