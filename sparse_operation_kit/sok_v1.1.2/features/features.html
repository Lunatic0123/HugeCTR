<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Features in SparseOperationKit &mdash; SparseOperationKit  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Get Started With SparseOperationKit" href="../get_started/get_started.html" />
    <link rel="prev" title="SparseOperationKit" href="../intro_link.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> SparseOperationKit
          </a>
              <div class="version">
                1.1.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro_link.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-parallelism-gpu-embedding-layer">Model-Parallelism GPU Embedding Layer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sparse-embedding-layer">Sparse Embedding Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#distributed-sparse-embedding">Distributed Sparse Embedding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dense-embedding-layer">Dense Embedding Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#all2all-dense-embedding">All2All Dense Embedding</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/get_started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples &amp; Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance/index.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_vars/env_vars.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues/issues.html">Known Issues</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SparseOperationKit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Features in SparseOperationKit</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/features/features.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="features-in-sparseoperationkit">
<h1>Features in SparseOperationKit<a class="headerlink" href="#features-in-sparseoperationkit" title="Permalink to this headline"></a></h1>
<p>The detailed information about the features in SparseOperationKit.</p>
<section id="model-parallelism-gpu-embedding-layer">
<h2>Model-Parallelism GPU Embedding Layer<a class="headerlink" href="#model-parallelism-gpu-embedding-layer" title="Permalink to this headline"></a></h2>
<p>As described in <a class="reference external" href="https://nvidia-merlin.github.io/HugeCTR/sparse_operation_kit/master/intro_link.html#features">Introduction Section</a>, SOK provides GPU Embedding Layers which works in model-parallelism manner. And it does not require any further data transformation from model-parallelism to data-parallism.</p>
<p>There are several different GPU Embedding Layers in SOK, which are implemented with different algorithms. These embedding layers can work in single machine or multiple machines.
<img alt="avatar" src="../_images/workflow_of_embeddinglayer.png" /></p>
<section id="sparse-embedding-layer">
<h3>Sparse Embedding Layer<a class="headerlink" href="#sparse-embedding-layer" title="Permalink to this headline"></a></h3>
<p>Sparse embedding layer is equivalent to <code class="docutils literal notranslate"><span class="pre">tf.nn.embedding_lookup_sparse</span></code> except the sparse embedding layers in SOK works in MP manner. The supported combiner in SOK sparse embedding layers are <code class="docutils literal notranslate"><span class="pre">Mean</span></code> and <code class="docutils literal notranslate"><span class="pre">Sum</span></code>.</p>
<section id="distributed-sparse-embedding">
<h4>Distributed Sparse Embedding<a class="headerlink" href="#distributed-sparse-embedding" title="Permalink to this headline"></a></h4>
<p>This sparse embedding will distribute each key based on <code class="docutils literal notranslate"><span class="pre">gpu_id</span> <span class="pre">=</span> <span class="pre">key</span> <span class="pre">%</span> <span class="pre">gpu_num</span></code>. For example, if there are 8 GPUs, then <code class="docutils literal notranslate"><span class="pre">key=1000</span></code> will be distributed to GPU-0, <code class="docutils literal notranslate"><span class="pre">key=1001</span></code> will be distributed to GPU-1. The following picture depicts its forward propagation process.</p>
<a class="bg-primary reference internal image-reference" href="../_images/distributed_sparse_embedding.png"><img alt="../_images/distributed_sparse_embedding.png" class="bg-primary align-center" src="../_images/distributed_sparse_embedding.png" style="width: 50%;" /></a>
<br>
To reduce the overhead of multiple embedding tables' looking up, where their embedding vector size are the same, Distributed sparse embedding combines multiple embedding tables as one huge embedding table. Each tiny embedding table is called slot, which is also known as feature-field. And the input keys for different embedding tables should be unified encoded.
<p>When conducting reduction of embedding vectors intra slots (feature-fields), collective operation <code class="docutils literal notranslate"><span class="pre">Reduce-Scatter</span></code> will be used. And <code class="docutils literal notranslate"><span class="pre">All-Gather</span></code> is used for their gradients backward propagation.</p>
</section>
</section>
<section id="dense-embedding-layer">
<h3>Dense Embedding Layer<a class="headerlink" href="#dense-embedding-layer" title="Permalink to this headline"></a></h3>
<p>Dense embedding layer is equivalent to <code class="docutils literal notranslate"><span class="pre">tf.nn.embedding_lookup</span></code> except the dense embedding layers in SOK works in MP manner.</p>
<section id="all2all-dense-embedding">
<h4>All2All Dense Embedding<a class="headerlink" href="#all2all-dense-embedding" title="Permalink to this headline"></a></h4>
<p>This dense embedding will distribute each key based on <code class="docutils literal notranslate"><span class="pre">gpu_id</span> <span class="pre">=</span> <span class="pre">key</span> <span class="pre">%</span> <span class="pre">gpu_num</span></code>. For example, if there are 8 GPUs, then <code class="docutils literal notranslate"><span class="pre">key=1000</span></code> will be distributed to GPU-0, <code class="docutils literal notranslate"><span class="pre">key=1001</span></code> will be distributed to GPU-1. The following picture depicts its forward propagation process.</p>
<a class="bg-primary reference internal image-reference" href="../_images/all2all_dense_embedding.png"><img alt="../_images/all2all_dense_embedding.png" class="bg-primary align-center" src="../_images/all2all_dense_embedding.png" style="width: 50%;" /></a>
<br>
<p>To reduce the overhead of multiple embedding tables’ looking up, where their embedding vector size are the same, All2All dense embedding combines multiple embedding tables as one huge embedding table. Each tiny embedding table is called slot, which is also known as feature-field. And the input keys for different embedding tables should be unified encoded.</p>
<p>In the forward propagation, <code class="docutils literal notranslate"><span class="pre">All2All</span></code> will be used to exchange keys among all GPUs, then another <code class="docutils literal notranslate"><span class="pre">All2All</span></code> will be used to exchange embedding vectors among all GPUs. In the backward propagation, <code class="docutils literal notranslate"><span class="pre">All2All</span></code> will be used to exchange top gradients among all GPUs.</p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../intro_link.html" class="btn btn-neutral float-left" title="SparseOperationKit" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../get_started/get_started.html" class="btn btn-neutral float-right" title="Get Started With SparseOperationKit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    master: sok_v1.1.2
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../sok_v1.0.0/features/features.html">sok_v1.0.0</a></dd>
      <dd><a href="../../sok_v1.1.0/features/features.html">sok_v1.1.0</a></dd>
      <dd><a href="../../sok_v1.1.1/features/features.html">sok_v1.1.1</a></dd>
      <dd><a href="features.html">sok_v1.1.2</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>